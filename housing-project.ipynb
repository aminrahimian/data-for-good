{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4666d501-d785-4311-89ca-2ee739cab506",
   "metadata": {},
   "source": [
    "# Fair Housing Project\n",
    "### Assigned by Bob Gradeck of the Western PA Data Conservancy\n",
    "Tara Schroth, Stephen Vandrak, Gloria Givler, Annie Goodwin  \n",
    "\n",
    "### Project Objective\n",
    "Currently, the affordable housing initiative struggles to place property bids quickly, due to bureaucracy inherent in the organization (working with government resources, etc). Our objective with this project is to establish a list of property owners that may be selling multi-unit properties in the near future. That way, the affordable housing initiative can reach out proactively to these owners and potentially strike a deal to purchase properties before they hit the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde06fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.3.0-py3-none-any.whl (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting geographiclib<3,>=1.52\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.3.0\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.3 MB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.11.0 tenacity-8.1.0\n"
     ]
    }
   ],
   "source": [
    "#import all necessary modules and packages\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"example app\")\n",
    "!pip install plotly\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a472f08-2230-43d4-980d-f3c871809421",
   "metadata": {},
   "source": [
    "## Importing, cleaning, and merging the datasets\n",
    "\n",
    "After reading in the sales and assessments datasets and dropping unwanted columns, we wanted to narrow the assessments dataset down to only the properties we are interested in. \n",
    "\n",
    "We decided to filter by the feature \"USEDESC\" (use description). We weren't interested in single-family homes, multi-family homes such as duplexes, condominum units, or any other types of residential properties that could not easily be converted to low-income housing. We decided that we were only interested in properties with the following use descriptions:\n",
    "- APART:40+ UNITS\n",
    "- APART:20-39 UNITS\n",
    "- APART: 5-19 UNITS\n",
    "- DWG APT CONVERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f520af-8883-4c68-ad9e-d6146b255bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARID</th>\n",
       "      <th>PROPERTYHOUSENUM</th>\n",
       "      <th>PROPERTYFRACTION</th>\n",
       "      <th>PROPERTYADDRESSDIR</th>\n",
       "      <th>PROPERTYADDRESSSTREET</th>\n",
       "      <th>PROPERTYADDRESSSUF</th>\n",
       "      <th>PROPERTYADDRESSUNITDESC</th>\n",
       "      <th>PROPERTYUNITNO</th>\n",
       "      <th>PROPERTYCITY</th>\n",
       "      <th>PROPERTYSTATE</th>\n",
       "      <th>...</th>\n",
       "      <th>MUNIDESC</th>\n",
       "      <th>RECORDDATE</th>\n",
       "      <th>SALEDATE</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DEEDBOOK</th>\n",
       "      <th>DEEDPAGE</th>\n",
       "      <th>SALECODE</th>\n",
       "      <th>SALEDESC</th>\n",
       "      <th>INSTRTYP</th>\n",
       "      <th>INSTRTYPDESC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1075F00108000000</td>\n",
       "      <td>4720</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>HIGHPOINT</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GIBSONIA</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>Hampton</td>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>15020</td>\n",
       "      <td>356</td>\n",
       "      <td>3</td>\n",
       "      <td>LOVE AND AFFECTION SALE</td>\n",
       "      <td>DE</td>\n",
       "      <td>DEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0011A00237000000</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOMBARD</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PITTSBURGH</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>3rd Ward - PITTSBURGH</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>TR15</td>\n",
       "      <td>00002</td>\n",
       "      <td>2</td>\n",
       "      <td>CITY TREASURER SALE</td>\n",
       "      <td>TS</td>\n",
       "      <td>TREASURER DEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0011J00047000000</td>\n",
       "      <td>1903</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>FORBES</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PITTSBURGH</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>1st Ward  - PITTSBURGH</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>4643.0</td>\n",
       "      <td>TR13</td>\n",
       "      <td>003</td>\n",
       "      <td>2</td>\n",
       "      <td>CITY TREASURER SALE</td>\n",
       "      <td>TS</td>\n",
       "      <td>TREASURER DEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0113B00029000000</td>\n",
       "      <td>479</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>ROOSEVELT</td>\n",
       "      <td>AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PITTSBURGH</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>2017-03-27</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16739</td>\n",
       "      <td>166</td>\n",
       "      <td>3</td>\n",
       "      <td>LOVE AND AFFECTION SALE</td>\n",
       "      <td>CO</td>\n",
       "      <td>CORRECTIVE DEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0119S00024000000</td>\n",
       "      <td>5417</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATRONA</td>\n",
       "      <td>WAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PITTSBURGH</td>\n",
       "      <td>PA</td>\n",
       "      <td>...</td>\n",
       "      <td>10th Ward - PITTSBURGH</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>27541.0</td>\n",
       "      <td>TR15</td>\n",
       "      <td>00059</td>\n",
       "      <td>GV</td>\n",
       "      <td>GOVERNMENT SALE</td>\n",
       "      <td>TS</td>\n",
       "      <td>TREASURER DEED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              PARID  PROPERTYHOUSENUM PROPERTYFRACTION PROPERTYADDRESSDIR  \\\n",
       "0  1075F00108000000              4720                                 NaN   \n",
       "1  0011A00237000000                 0                                 NaN   \n",
       "2  0011J00047000000              1903                                 NaN   \n",
       "3  0113B00029000000               479                                 NaN   \n",
       "4  0119S00024000000              5417                                 NaN   \n",
       "\n",
       "  PROPERTYADDRESSSTREET PROPERTYADDRESSSUF PROPERTYADDRESSUNITDESC  \\\n",
       "0             HIGHPOINT                 DR                     NaN   \n",
       "1               LOMBARD                 ST                     NaN   \n",
       "2                FORBES                AVE                     NaN   \n",
       "3             ROOSEVELT                AVE                     NaN   \n",
       "4               NATRONA                WAY                     NaN   \n",
       "\n",
       "  PROPERTYUNITNO PROPERTYCITY PROPERTYSTATE  ...                MUNIDESC  \\\n",
       "0            NaN     GIBSONIA            PA  ...               Hampton     \n",
       "1            NaN   PITTSBURGH            PA  ...   3rd Ward - PITTSBURGH   \n",
       "2            NaN   PITTSBURGH            PA  ...  1st Ward  - PITTSBURGH   \n",
       "3            NaN   PITTSBURGH            PA  ...              Bellevue     \n",
       "4            NaN   PITTSBURGH            PA  ...  10th Ward - PITTSBURGH   \n",
       "\n",
       "   RECORDDATE    SALEDATE     PRICE DEEDBOOK DEEDPAGE SALECODE  \\\n",
       "0  2012-09-27  2012-09-27  120000.0    15020      356        3   \n",
       "1  2015-01-06  2015-01-06    1783.0     TR15    00002        2   \n",
       "2  2012-10-26  2012-10-26    4643.0     TR13      003        2   \n",
       "3  2017-03-27  2017-03-06       0.0    16739      166        3   \n",
       "4  2015-02-04  2015-02-04   27541.0     TR15    00059       GV   \n",
       "\n",
       "                  SALEDESC INSTRTYP     INSTRTYPDESC  \n",
       "0  LOVE AND AFFECTION SALE       DE             DEED  \n",
       "1      CITY TREASURER SALE       TS   TREASURER DEED  \n",
       "2      CITY TREASURER SALE       TS   TREASURER DEED  \n",
       "3  LOVE AND AFFECTION SALE       CO  CORRECTIVE DEED  \n",
       "4          GOVERNMENT SALE       TS   TREASURER DEED  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in sales data and look at first 5 rows\n",
    "sales=pd.read_csv('SalesData.csv', low_memory=False)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb0a10f-920a-421a-81d9-36cf6640011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sale date from string to date\n",
    "sales['SALEDATE']=pd.to_datetime(sales['SALEDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8807d768-a1c9-42f0-8006-45c984dba1ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AssessmentData.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/n484d0ds1r321tdgcxpb6b100000gn/T/ipykernel_57294/1247948412.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#path='C:\\\\Users\\\\Tara\\\\OneDrive - University of Pittsburgh\\\\FALL 2022\\\\ENGR 1171\\\\Project Housing Data\\\\'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0massessment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AssessmentData.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0massessment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AssessmentData.csv'"
     ]
    }
   ],
   "source": [
    "# Read in assessments data and look at first 5 rows\n",
    "#change path to work with your file setup\n",
    "#path='C:\\\\Users\\\\Tara\\\\OneDrive - University of Pittsburgh\\\\FALL 2022\\\\ENGR 1171\\\\Project Housing Data\\\\'\n",
    "\n",
    "assessment=pd.read_csv('AssessmentData.csv', low_memory=False)\n",
    "assessment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be03f65-c7d9-4815-8b2b-63435102fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns and look at first 5 rows\n",
    "assessment=assessment[['PARID','PROPERTYHOUSENUM','PROPERTYFRACTION','PROPERTYADDRESS','PROPERTYUNIT','MUNIDESC','OWNERDESC','CLASSDESC', \n",
    "'USEDESC', 'LOTAREA','HOMESTEADFLAG','FARMSTEADFLAG','ABATEMENTFLAG','SALEDATE','SALEPRICE','SALEDESC','PREVSALEDATE','PREVSALEPRICE',\n",
    " 'PREVSALEDATE2','PREVSALEPRICE2','CHANGENOTICEADDRESS1','CHANGENOTICEADDRESS2','CHANGENOTICEADDRESS3','CHANGENOTICEADDRESS4',\n",
    "'STYLEDESC','STORIES','YEARBLT','CDUDESC',\n",
    "]]\n",
    "assessment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956304b0-b352-4b05-8ad4-f51b1084542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow it down to properties we’re interested in\n",
    "# Filter by USEDESC (see above explanation of choices)\n",
    "assessment=assessment.loc[\n",
    "    (assessment['USEDESC'].isin(['APART:40+ UNITS','APART:20-39 UNITS','APART:5-19 UNITS','DWG APT CONVERSION']))\n",
    "]\n",
    "assessment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a05263-1fb0-41bf-a8e4-026435180cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two datasets\n",
    "# Pull the latest sale date for each property (Tara’s code)\n",
    "salesgrouped=sales[['PARID','SALEDATE']].groupby('PARID').agg({'SALEDATE':'max'}).reset_index().rename(columns={'SALEDATE':'FINALSALEDATE'})\n",
    "df=pd.merge(assessment,salesgrouped,how='left',on='PARID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a390499-4698-4a8d-8ea1-7ae61f40a44c",
   "metadata": {},
   "source": [
    "## Determining the owners that have purchased the most properties in the past 2 years\n",
    "\n",
    "We wanted to determine who has purchased the most properties in the past 2 years, with the goal of seeing which companies are currently growing their real-estate portfolios. They are less likely to be selling a lot of properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb5744-4dbe-4884-af1e-41039c65a591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter to last 2 years of sales only, look at first 5 rows\n",
    "last2years=df.loc[df['FINALSALEDATE']>pd.Timestamp('2020-09-22 00:00:00')]\n",
    "last2years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47851fb-db1a-425b-bc69-f04afa99e921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find owners who have purchased at least 3 multiunit properties in the last 2 years and look at df\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "last2years['OwnerInfo']=last2years['CHANGENOTICEADDRESS1'].astype(str)+' '+last2years['CHANGENOTICEADDRESS2'].astype(str)+' '+last2years['CHANGENOTICEADDRESS3'].astype(str)+' '+last2years['CHANGENOTICEADDRESS4'].astype(str)\n",
    "buyersofmany=last2years[['PARID','OwnerInfo']].drop_duplicates().groupby('OwnerInfo').size().reset_index(name='NumPropertiesBought')\n",
    "buyersofmany=buyersofmany.loc[(~buyersofmany['OwnerInfo'].isna())&(buyersofmany['NumPropertiesBought']>2)]\n",
    "last2years.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc73e15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by the owner to get a list of owners\n",
    "print('There are', len(buyersofmany), 'owners that have purchased at least three multiunit residential properties in the past 2 years')\n",
    "buyersofmany.sort_values(['NumPropertiesBought'],ascending=[False])\n",
    "\n",
    "# Owner's contact info (phone number/primary residence) is not available in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c943d3d0-8b82-43e8-b3b6-bc74a17159dd",
   "metadata": {},
   "source": [
    "## Determining the owners that currently own the most properties\n",
    "\n",
    "We wanted to determine who currently owns the most properties, based on the property assessments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c05d16-845a-4b40-8550-e987a84aff4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at all data we have\n",
    "alltime=df\n",
    "alltime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddee6c-43f5-4a3c-87ad-e9f55ed8e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find owners who have purchased a multiunit property, ever, and look at df\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "alltime['OwnerInfo']=alltime['CHANGENOTICEADDRESS1'].astype(str)+' '+alltime['CHANGENOTICEADDRESS2'].astype(str)+' '+alltime['CHANGENOTICEADDRESS3'].astype(str)+' '+alltime['CHANGENOTICEADDRESS4'].astype(str)\n",
    "ownersofmany=alltime[['PARID','OwnerInfo']].drop_duplicates().groupby('OwnerInfo').size().reset_index(name='NumPropertiesOwned')\n",
    "ownersofmany=ownersofmany.loc[(~ownersofmany['OwnerInfo'].isna())&(ownersofmany['NumPropertiesOwned']>5)]\n",
    "alltime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5b988-b9df-4ef2-a5c8-b16460f8727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the owner to get a list of owners\n",
    "print('There are', len(ownersofmany), 'owners that have bought at least 5 multiunit residential properties, ever')\n",
    "ownersofmany.sort_values(['NumPropertiesOwned'],ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25cee7-0b0b-4390-a487-e415aeb39543",
   "metadata": {},
   "source": [
    "# Remove buyers of many from owners of many\n",
    "We are interested in companies who currently own a lot of multiunit properties, but aren't recently buying a lot more multiunit properties. We want to eliminate those individuals, as they are more likely to be competitors of the fair housing initiative in terms of placing bids on new properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb476c-e1a4-4ac0-ad2a-8eee5fc6dfc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merging the dataframes and dropping duplicates, printing the list - changed to eliminate the NA # bought col\n",
    "# interestingowners=(ownersofmany.merge(buyersofmany, on='OwnerInfo', how='left', indicator=True)\n",
    "#      .query('_merge == \"left_only\"')\n",
    "#      .drop('_merge', 1))\n",
    "interestingowners=ownersofmany.loc[~ownersofmany['OwnerInfo'].isin(buyersofmany['OwnerInfo'])]\n",
    "print('There are', len(interestingowners), 'owners that have bought at least 5 multiunit residential properties, fewer than 3 of which were bought in the last year.')\n",
    "interestingowners.sort_values(['NumPropertiesOwned'],ascending=[False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f73f628-5c64-4915-b9f4-f849a4969049",
   "metadata": {},
   "source": [
    "### Note: the code block below is optional!\n",
    "\n",
    "Only run the code block below if you have new houses and need their coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd64f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the addresses of all properties owned by the above owners\n",
    "assessmentcopy=pd.read_csv('AssessmentData1.csv')\n",
    "ownerproperties=df.loc[df['OwnerInfo'].isin(interestingowners['OwnerInfo'])]\n",
    "assessmentcopy=assessmentcopy.loc[assessmentcopy['PARID'].isin(ownerproperties['PARID'])]\n",
    "assessmentcopy['Address']=assessmentcopy['PROPERTYHOUSENUM'].astype(str)+' '+assessmentcopy['PROPERTYADDRESS'].astype(str)+' '+assessmentcopy['PROPERTYCITY'].astype(str)+' '+assessmentcopy['PROPERTYSTATE'].astype(str)+' '+assessmentcopy['PROPERTYZIP'].astype(int).astype(str)\n",
    "housestomap=assessmentcopy[['PARID','Address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02993d7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use geopy to get the lat and lon coordinates for each house so we can map them\n",
    "housestomap['Lat']=''\n",
    "housestomap['Lon']=''\n",
    "housestomap=housestomap.reset_index()\n",
    "for i in range(len(housestomap['Address'])):\n",
    "    data=geolocator.geocode(housestomap.loc[i,'Address'])\n",
    "    try:\n",
    "        housestomap.loc[i,'Lat']=data.raw.get(\"lat\")\n",
    "        housestomap.loc[i,'Lon']=data.raw.get(\"lon\")\n",
    "    except:\n",
    "        continue\n",
    "housestomap.to_csv('housestomap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had to manually fill in some of the coordinates, hence the read.csv\n",
    "#can use google maps, and right click on the pin to get the lat and lon\n",
    "housestomap=pd.read_csv('housestomap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d36e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the owner address and number of properties owned with the coordinates\n",
    "mergedhousestomap=pd.merge(housestomap,df[['PARID','OwnerInfo']],how='left',on='PARID')\n",
    "# Create a new df that adds on the number of properties owned by each owner\n",
    "mergedhousestomap2=pd.merge(mergedhousestomap,interestingowners,how='left',on='OwnerInfo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regular map of all the houses\n",
    "fig = px.scatter_mapbox(mergedhousestomap,lat='Lat',lon='Lon', hover_name=\"OwnerInfo\")\n",
    "fig.update_layout(title = 'Map of Possible Units', title_x=0.5)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5aa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map where the houses are, color coded by how many properties their owner owns\n",
    "fig = px.scatter_mapbox(mergedhousestomap2,lat='Lat',lon='Lon', hover_name=\"OwnerInfo\",color='NumPropertiesOwned',color_continuous_scale='Bluered_r')\n",
    "fig.update_layout(title = 'Map of Possible Units', title_x=0.5)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6a425-309b-46c1-a0a0-1dc44d4ad28c",
   "metadata": {},
   "source": [
    "## Incorporating Community Sites Onto the Map\n",
    "On the Western Pennsylvania Regional Data Center website, we found a dataset that is a list of community assets in the county. Examples of assets include (but are not limited to) gas stations, barbers, doctor's offices, and grocery stores. We thought that it may be useful to incorporate some of these locations into the map view, so that specific properties could be investigated as good future low-income housing sites based on the infrastructure nearby. Not everyone living in low-income housing will have access to a car, so ensuring that some level of resources are walkable will set residents up for less hardship.\n",
    "\n",
    "We decided to only include the resources we viewed as most critical to daily life, which were the following:\n",
    "- acha_community_sites (Allegheny County Housing Authority Community Centers)\n",
    "- achd_clinics (Allegheny County Health Department Clinics)\n",
    "- child_care_centers\n",
    "- dentists\n",
    "- doctors_offices\n",
    "- family_support_centers\n",
    "- food_banks\n",
    "- health_centers\n",
    "- laundromats\n",
    "- libraries\n",
    "- pharmacies\n",
    "- rec_centers\n",
    "- senior_centers\n",
    "- supermarkets\n",
    "- va_facilities (Veterans Affairs Facilities)\n",
    "- wic_offices (Women, Infants, and Children Offices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149f80c-9797-44e9-b6be-9a9af60a38f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in community assets data, drop unwanted columns, and look at first 5 rows\n",
    "communityassets=pd.read_csv('CommunityAssets.csv', low_memory=False)\n",
    "communityassets=communityassets[['name','asset_type','street_address','city','state','latitude','longitude']]\n",
    "communityassets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111739ad-9753-4b55-9a4d-0481ba8b8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrow it down to assets we’re interested in\n",
    "# Filter by asset_type (see above explanation of choices)\n",
    "communityassets=communityassets.loc[\n",
    "    (communityassets['asset_type'].isin(['acha_community_sites','achd_clinics','child_care_centers','dentists', 'doctors_offices',\n",
    "                                         'family_support_centers','food_banks','health_centers','laundromats','libraries','pharmacies',\n",
    "                                        'rec_centers','senior_centers','supermarkets','va_facilities','wic_offices']))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b825491-a709-4eb0-81b4-77dde2db68bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating a more general variable of asset class\n",
    "communityassets['asset_class'] = communityassets.loc[:, 'asset_type']\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['acha_community_sites'], 'community_centers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['achd_clinics'], 'healthcare_providers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['child_care_centers'], 'child_resources')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['dentists'], 'healthcare_providers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['doctors_offices'], 'healthcare_providers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['family_support_centers'], 'child_resources')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['food_banks'], 'food_sources')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['health_centers'], 'healthcare_providers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['laundromats'], 'laundromats')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['libraries'], 'community_centers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['pharmacies'], 'pharmacies')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['rec_centers'], 'community_centers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['senior_centers'], 'community_centers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['supermarkets'], 'food_sources')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['va_facilities'], 'healthcare_providers')\n",
    "communityassets['asset_class'] = communityassets['asset_class'].replace(['wic_offices'], 'wic_offices')\n",
    "communityassets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde5f9e4-8316-4cff-8302-a79c771c82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regular map of all the community assets, colored by asset_type\n",
    "fig = px.scatter_mapbox(communityassets,lat='latitude',lon='longitude', hover_name=\"name\", color='asset_class')\n",
    "fig.update_layout(title = 'Map of Community Assets', title_x=0.5)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c60453-52ac-4bd2-a38f-bf21117829cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe and change names of columns to match eachother\n",
    "newcommunityassets=communityassets.copy()\n",
    "newcommunityassets.rename(columns = {'latitude':'Lat','longitude':'Lon','street_address':'Address'}, inplace = True)\n",
    "newcommunityassets.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1786d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge housing data with community assets\n",
    "comboassetandhouses=outer_merged = pd.merge(mergedhousestomap2, newcommunityassets, how=\"outer\", on=[\"Lat\", \"Lon\",\"Address\"])\n",
    "comboassetandhouses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda63636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear NaN Values and rename to match \n",
    "comboassetandhouses1=comboassetandhouses.fillna(0)\n",
    "comboassetandhouses1['asset_class']=comboassetandhouses1['asset_class'].replace(0,'property')\n",
    "\n",
    "#Create new column to differentiate between houses and community assets\n",
    "comboassetandhouses1['HouseAssets'] = [3 if x =='property' else 1 for x in comboassetandhouses1['asset_class']]\n",
    "comboassetandhouses1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa98161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a regular map of all the community assets and houses, colored and sized by asset_type\n",
    "fig = px.scatter_mapbox(comboassetandhouses1,lat='Lat',lon='Lon', hover_name=\"Address\",color='asset_class',size='HouseAssets',size_max=7)\n",
    "fig.update_layout(title = 'Map of Community Assets and Properties', title_x=0.5)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e000c99",
   "metadata": {},
   "source": [
    "# Potential Challenges & Ethical Implications\n",
    "\n",
    "After analyzing the data and coming up with the list of properties/owners, we decided it would be beneficial to have a discussion on the potential challenges and ethical dilemmas that arise within the affordable housing community. \n",
    "\n",
    "A potential challenge that could come from the non-profit approaching potential housing deals is that the property owners could refuse to sell to them and go with a higher bidder. What is the highest amount that the organization will/can offer for the properties? What is more important, profiting or creating affordable housing for lower income households? \n",
    "\n",
    "\n",
    "##Is Housing a human right?\n",
    "\n",
    "Read this article: https://housingmatters.urban.org/articles/naming-housing-human-right-first-step-solving-housing-crisis\n",
    "\n",
    "Article 25 of the United Nations Universal Declaration of Human Rights states: \n",
    "\n",
    "\"Everyone has the right to a standard of living adequate for the health and well-being of himself and of his family, including food, clothing, housing and medical care and...\"\n",
    "\n",
    "If housing has been declared as a human right, then why do we treat it as a commodity? What ideas do you have to ensuring access to affordable housing?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a007d4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de9072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
