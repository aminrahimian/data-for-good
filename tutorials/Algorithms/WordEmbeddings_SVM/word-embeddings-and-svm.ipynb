{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113f8932",
   "metadata": {},
   "source": [
    "# Support Vector Machine\n",
    "\n",
    "## Background reading:\n",
    "*Intro to Statistical Learning*: Chapter 9， Section 9.1, 9.2, 9.3, Support Vector Machine(Page 368-385)\n",
    "\n",
    "*Ethical Algorithm*: Chapter 2, Algorithmic Fairness, Bias by Analogy, (Page 57-63)\n",
    "\n",
    "## Dataset:\n",
    "**2 Attributes:**\n",
    "\n",
    "1. Words (Specific vocabularies that are feminine, masculine or neutral)\n",
    "2. Category\n",
    "\n",
    "Datasets comes from: https://link.springer.com/article/10.3758/BF03195592\n",
    "\n",
    "This tutorial aims at using SVM to classify whether a word is gender-biased. To deal with vocabulary in computer, background of Natural Language Processing is discussed here for you to read if you are interested in.\n",
    "\n",
    "## Essence of Data\n",
    "\n",
    "### Before Algorithms:Basic Concepts\n",
    "\n",
    "In this section, we will first introduce some basic concepts to help you understand what is support vector machine.\n",
    "\n",
    "**Hyperplane**\n",
    "\n",
    "Def: A subspace which has one less dimension than its space.\n",
    "E.g.,  In a 2-dimensional space, a hyperplane is in one dimension (a line); In a 3-dimensional space, a hyperplane is in two dimensions (a plane)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c1e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_files = ['.RData', '.RHistory', '.RProfile']\n",
    "import pathlib\n",
    "for rf in r_files:\n",
    "    p = pathlib.Path.cwd() / rf\n",
    "    try:\n",
    "        p.rename(p.with_suffix('.ignore'))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "import rpy2\n",
    "from rpy2 import robjects\n",
    "for rf in r_files:\n",
    "    p = pathlib.Path.cwd() / rf\n",
    "    p = p.with_suffix('.ignore')\n",
    "    try:\n",
    "        p.rename(p.with_suffix(''))\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa6eedff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "\n",
    "#This is used here to allow us to use both Python and R in Jupyter Notebook\n",
    "# Before Running it, make sure that the IR kernel is installed to jupyter. You can also run these codes on r-studio for r languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e01f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored from cffi callback <function _consolewrite_ex at 0x000002275F2D3940>:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\rinterface_lib\\callbacks.py\", line 133, in _consolewrite_ex\n",
      "    s = conversion._cchar_to_str_with_maxlen(buf, n, _CCHAR_ENCODING)\n",
      "  File \"C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py\", line 138, in _cchar_to_str_with_maxlen\n",
      "    s = ffi.string(c, maxlen).decode(encoding)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd4 in position 0: invalid continuation byte\n",
      "Exception ignored from cffi callback <function _consolewrite_ex at 0x000002275F2D3940>:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\rinterface_lib\\callbacks.py\", line 133, in _consolewrite_ex\n",
      "    s = conversion._cchar_to_str_with_maxlen(buf, n, _CCHAR_ENCODING)\n",
      "  File \"C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py\", line 138, in _cchar_to_str_with_maxlen\n",
      "    s = ffi.string(c, maxlen).decode(encoding)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd4 in position 0: invalid continuation byte\n",
      "Exception ignored from cffi callback <function _consolewrite_ex at 0x000002275F2D3940>:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\rinterface_lib\\callbacks.py\", line 133, in _consolewrite_ex\n",
      "    s = conversion._cchar_to_str_with_maxlen(buf, n, _CCHAR_ENCODING)\n",
      "  File \"C:\\Users\\Yixuan\\anaconda3\\lib\\site-packages\\rpy2\\rinterface_lib\\conversion.py\", line 138, in _cchar_to_str_with_maxlen\n",
      "    s = ffi.string(c, maxlen).decode(encoding)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xd4 in position 1: invalid continuation byte\n",
      "R[write to console]: The following object is masked from 'package:ggplot2':\n",
      "\n",
      "    last_plot\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:graphics':\n",
      "\n",
      "    layout\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <span>BoolVector with 1 elements.</span>\n",
       "        <table>\n",
       "        <tbody>\n",
       "          <tr>\n",
       "          \n",
       "            <td>\n",
       "                   1\n",
       "            </td>\n",
       "          \n",
       "          </tr>\n",
       "        </tbody>\n",
       "        </table>\n",
       "        "
      ],
      "text/plain": [
       "<rpy2.robjects.vectors.BoolVector object at 0x0000022764462CC0> [RTYPES.LGLSXP]\n",
       "R classes: ('logical',)\n",
       "[       1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before run the code, make sure that you have already installed ggplot2 and plotly packages. \n",
    "# Load the package for ggplot2, which is an excellent package to draw statistical graphs\n",
    "%R require('ggplot2')\n",
    "# Package plotly is used for creating 3-d plots\n",
    "%R require('plotly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a020f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a data frame to help understand the hyperplane in 2-d/3-d\n",
    "import pandas as pd\n",
    "df2 = pd.DataFrame({\n",
    "    'x':[0,1,1,2,2,3,3,4,4,4,5,5,6],\n",
    "    'y':[5.2,3.8,4.9,2.5,5.5,3,4,2.2,3.4,4.6,3,2.1,1.5]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5549d909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i df2\n",
    "df2$above_below=ifelse(df2$y+0.5*df2$x-5>0,1,0)\n",
    "df2\n",
    "ggplot(df2, aes(x=x,y=y,col=above_below))+\n",
    "       geom_point() + geom_abline(slope=-0.5,intercept=5,col='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02074cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\n",
    "    'x':[1,2,2,3,4,6,5,3,3],\n",
    "    'y':[1,2,3,3,4,4,5,2,1],\n",
    "    'z':[3,4,-7,-2,-4,-3,-12,-7,-9]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d33c984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df3\n",
    "df3$above_below=ifelse(df3$x+df3$y+df3$z>0,1,0)\n",
    "df3\n",
    "input1=as.matrix(seq(1,6,0.1))\n",
    "input2=as.matrix(seq(1,6,0.1))\n",
    "input3=as.matrix(-input1-input2)\n",
    "\n",
    "plot_ly(x=df3$x,y=df3$y,z=df3$z,type=\"scatter3d\", mode=\"markers\", color=df3$above_below)%>%\n",
    "add_surface(x=input1,y=input2,z=input3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760c094",
   "metadata": {},
   "source": [
    "The mathematical expression of the hyperplane in p-dimensions is:\n",
    "\n",
    "<div align = 'center'><font size = '6'>$\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_px_p=0$</font></div>\n",
    "\n",
    "From the graph above, the data points can be separated by a hyperplane in the space. When $\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_px_p>0$, the data points lie on one side of the hyperplane, while they lie on the other side when $\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_px_p<0$. It is reasonable to find out this natural classifier to do classification.\n",
    "\n",
    "**Maximal Margin Classifier and Support Vector Classifier**\n",
    "\n",
    "Margin: the perpendicular distance from the observation to the hyperplane\n",
    "\n",
    "Maximal Margin Classifier: Among all the possible hyperplanes that can separate the data into categorizes, select the one that come up with the maximal margin.\n",
    "\n",
    "**Support Vectors:**\n",
    "\n",
    "In the space, there are some observations points that have equal distance from the maximal margin hyperplane. For example, in this graph there are some support vectors lie on the dashed line, with their distances shown as arrows. These observations are called support vectors since they “support” the hyperplane (when the support vectors move a little bit, the hyperplane will move as well, while the movement of other observations does not affect the hyperplane)\n",
    "\n",
    "![Figure 9.3 From Textbook Page 372](./fig/SVM&WE/fig1.png)\n",
    "\n",
    "**Support Vector Classifiers**\n",
    "\n",
    "Sometimes the datasets cannot be separated perfectly by the hyperplane. In such case, support vector classifier is considered, which is a more generalized case of maximal margin classifier. We allow some of the observations to be on the wrong side of the margin/hyperplane. Details of the mathematical expression: page 375.\n",
    "\n",
    "![Figure 9.6 From Textbook Page 376](./fig/SVM&WE/fig2.png)\n",
    "\n",
    "Left: observation 1 and 8 are on the wrong side of the margin\n",
    "Right: observation 11 and 12 are on the wrong side of the hyperplane\n",
    "\n",
    "**Support Vector Machine:**\n",
    "\n",
    "Sometimes the datasets cannot be separated by using a linear hyperplane, even we allow some of the observations to be on the wrong side. For example, it is impossible to build up a classifier by using a linear boundary for the data below. Thus, we need some techniques to increase the complexity and the non-linearity of the model to make good predictions. The technique is called kernel.\n",
    "\n",
    "![Figure 9.8 From Textbook Page 379](./fig/SVM&WE/fig3.png)\n",
    "\n",
    "What is **kernel**?\n",
    "\n",
    "By using some kernel function to transform the data into, for example, higher dimensions, to ensure that the inner product is the same as the previous one, then to make it separable in the new case.\n",
    "\n",
    "Examples of kernel functions:\n",
    "Polynomial, Gaussian, RBF, Sigmoid, Radial, etc.\n",
    "\n",
    "**Which kernel to choose?**\n",
    "\n",
    "This is a very tricky problem and could be one of the drawbacks of SVM, since there are no good rules to follow. Sometimes you should try a lot of different kernel functions to reach out one best model. For example, for the data graph above, both kernel function of polynomial of degree 3 (left) and radial (right) works well.\n",
    "\n",
    "![Figure 9.9 From Textbook Page 383](./fig/SVM&WE/fig4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b87acd",
   "metadata": {},
   "source": [
    "### Before Application: Background of Natural Language Processing\n",
    "\n",
    "In this section, we will cover topics related to natural language processing(NLP)\n",
    "\n",
    "**Word Processing**\n",
    "\n",
    "\tWhen dealing with the language (known as Natural Language Processing), unfortunately the computer cannot handle the characters/vocabularies and does not understand the meaning of them (Remember when the computer processes the characters, it will transform them into digital data by some encoding form such as Unicode or UTF-8). Consequently, it is necessary to translate the language into digital data before the computer can analyze. The most common techniques include one-hot encoding and word embedding.\n",
    "\n",
    "Here are two useful articles related to the background:\n",
    "\n",
    "**Power of NLP**\n",
    "\n",
    "https://hbr.org/2022/04/the-power-of-natural-language-processing\n",
    "\n",
    "**NLP and Google Translate**\n",
    "\n",
    "https://www.kdnuggets.com/2017/09/machine-learning-translation-google-translate-algorithm.html\n",
    "\n",
    "**What is word embedding?**\n",
    "\n",
    "\tWhen doing the natural language processing, associate a vector with a word where the vectors are learned from data. i.e., generate vectors that encodes the meaning of the words so that the words that are closed to each other in the space that we are interested are similar in their meanings. For example, in a space, we have a “gender” vectors and “plural” vectors. By adding a “female” vector to the vector “king/actor”, we obtain the vector “queen/actress”; by adding the “plural” vector we will obtain “kings/actors”\n",
    "\n",
    "![Words on different axises](./fig/SVM&WE/fig5.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40f1c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_we = pd.DataFrame({\n",
    "    'gender_axis':[1,1,3,3],\n",
    "    'plural_axis':[1,3,1,3]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2fb31f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i df_we\n",
    "\n",
    "ggplot(data=df_we) +\n",
    "    geom_point(mapping = aes(x = gender_axis, y = plural_axis), shape = 4, size = 6, col = \"red\") +\n",
    "    annotate(\"text\", x = 1.2, y = 1.2, label = \"king\") +\n",
    "    annotate(\"text\", x = 3.2, y = 1.2, label = \"queen\") +\n",
    "    annotate(\"text\", x = 1.2, y = 3.2, label = \"kings\") +\n",
    "    annotate(\"text\", x = 3.2, y = 3.2, label = \"queens\") +\n",
    "    scale_x_continuous(limits=c(0,4)) +\n",
    "    scale_y_continuous(limits=c(0,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01148885",
   "metadata": {},
   "source": [
    "https://www.ibm.com/blogs/research/2018/11/word-movers-embedding/\n",
    "\n",
    "![Words vectors in the space](./fig/SVM&WE/fig6.png)\n",
    "\n",
    "**Why word embeddings?**\n",
    "\n",
    "\tWhen doing natural language processing, the computer itself does not understand the real meaning behind the vocabularies. It only processing the digital data. Thus, when dealing with languages (or any other non-digital data), we should figure out a way to transform the data into digital data (encoding) so that the computer can understand and process with it, then we get the result by decoding it.\n",
    "\tThere are several different methods to transform the language. Another popular one is the one-hot encoding, which is also a common way. It consists of associating a unique integer index with every word and then turning the index into a binary vector of size of the vocabulary, while the other to be zero. i.e., the vector will be zeros except for that index to be 1. \n",
    "    \n",
    "![Examples of one-hot encoding and Word Embeddings](./fig/SVM&WE/fig7.png)\n",
    "\n",
    "\tHowever, you may think about the downsides of word embeddings. Imagine if there are some neutral vocabularies that do not imply any gender, but it is predicted to be a gender-specific word (which is a bias! Because the word itself does not have any gender-bias) For example, one model may encodes “muscles”, “Programmer” and “game” with vectors that have more “male” values of projection on the gender axis. Sometimes the insufficient of the data will aggravate the bias further.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d724c39a",
   "metadata": {},
   "source": [
    "### Example of Codes\n",
    "\n",
    "In this section we will try to use word embeddings and SVM as tools to process with words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82aec7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, Import all packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2582df5",
   "metadata": {},
   "source": [
    "*To make a word-embedding model, we will use gensim package which is sophisticated. To simplify understanding, we will use a pre-trained model (Word2Vec) by Google that contains millions of words that are trained based on its corpus. \n",
    "\n",
    "*The pre-trained model is described here: https://code.google.com/archive/p/word2vec/. The model contains millions of words with their vectors (thousands dimensions) with enormous size. \n",
    "\n",
    "**The pre-trained model can be downloaded from here:https://code.google.com/archive/p/word2vec/\n",
    "https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
    "**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383af829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x20739d8ff10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained model (It takes some time to run it cause the size is millions)\n",
    "# ! Download from website and store it\n",
    "word2vec_path = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "model = models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "# Notice that model is a \"Word2Vec\" pre-trained model object here\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7ee88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wife</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Princess</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bridesmaid</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pregnant</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bride</td>\n",
       "      <td>Feminine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Testosterone</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Husband</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Father</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Brother</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Uncle</td>\n",
       "      <td>Masculine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Vocabulary   Category\n",
       "0            Wife   Feminine\n",
       "1        Princess   Feminine\n",
       "2      Bridesmaid   Feminine\n",
       "3        Pregnant   Feminine\n",
       "4           Bride   Feminine\n",
       "..            ...        ...\n",
       "595  Testosterone  Masculine\n",
       "596       Husband  Masculine\n",
       "597        Father  Masculine\n",
       "598       Brother  Masculine\n",
       "599         Uncle  Masculine\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('WordEmbeddings.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f0a7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the vectors of the model\n",
    "word_dict = dict({})\n",
    "for index, key in enumerate(model.key_to_index):\n",
    "    word_dict[key] = model.get_vector(key)\n",
    "\n",
    "# Print\n",
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80db635a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The size is too large. Filter those that are useful\n",
    "new_dict = dict((k, word_dict[k]) for k in dataset['Vocabulary'] if k in word_dict)\n",
    "len(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d4119ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595\n"
     ]
    }
   ],
   "source": [
    "# Settle Database\n",
    "\n",
    "x_all = list()\n",
    "for x in new_dict.values():\n",
    "    x_all.append(x)\n",
    "\n",
    "print(len(x_all))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad14e255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = list()\n",
    "for y in dataset['Vocabulary']:\n",
    "    if y in new_dict.keys():\n",
    "        y_all.append(y)\n",
    "\n",
    "len(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56880c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size = 0.2, random_state = 43960)\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d44dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start SVM classifier\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "030bd77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the Accuracy\n",
    "svm_classifier.score(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28ddebbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the Accuracy\n",
    "svm_classifier.score(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa16092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an simple application of the Word2Vec package\n",
    "#resource: https://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.Yzu2pHbMJPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aa43479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports packeges\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f171f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"reviews_data.txt.gz\"\n",
    "\n",
    "with gzip.open ('reviews_data.txt.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b160f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a17100f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 22:57:18,469 : INFO : reading file reviews_data.txt.gz...this may take a while\n",
      "2022-10-04 22:57:18,470 : INFO : read 0 reviews\n",
      "2022-10-04 22:57:20,925 : INFO : read 10000 reviews\n",
      "2022-10-04 22:57:23,592 : INFO : read 20000 reviews\n",
      "2022-10-04 22:57:26,784 : INFO : read 30000 reviews\n",
      "2022-10-04 22:57:28,949 : INFO : read 40000 reviews\n",
      "2022-10-04 22:57:31,352 : INFO : read 50000 reviews\n",
      "2022-10-04 22:57:33,653 : INFO : read 60000 reviews\n",
      "2022-10-04 22:57:35,460 : INFO : read 70000 reviews\n",
      "2022-10-04 22:57:37,403 : INFO : read 80000 reviews\n",
      "2022-10-04 22:57:39,231 : INFO : read 90000 reviews\n",
      "2022-10-04 22:57:40,935 : INFO : read 100000 reviews\n",
      "2022-10-04 22:57:42,703 : INFO : read 110000 reviews\n",
      "2022-10-04 22:57:44,555 : INFO : read 120000 reviews\n",
      "2022-10-04 22:57:46,284 : INFO : read 130000 reviews\n",
      "2022-10-04 22:57:48,577 : INFO : read 140000 reviews\n",
      "2022-10-04 22:57:50,933 : INFO : read 150000 reviews\n",
      "2022-10-04 22:57:53,548 : INFO : read 160000 reviews\n",
      "2022-10-04 22:57:56,008 : INFO : read 170000 reviews\n",
      "2022-10-04 22:57:58,741 : INFO : read 180000 reviews\n",
      "2022-10-04 22:58:01,104 : INFO : read 190000 reviews\n",
      "2022-10-04 22:58:03,292 : INFO : read 200000 reviews\n",
      "2022-10-04 22:58:05,777 : INFO : read 210000 reviews\n",
      "2022-10-04 22:58:08,367 : INFO : read 220000 reviews\n",
      "2022-10-04 22:58:10,764 : INFO : read 230000 reviews\n",
      "2022-10-04 22:58:13,313 : INFO : read 240000 reviews\n",
      "2022-10-04 22:58:16,040 : INFO : read 250000 reviews\n",
      "2022-10-04 22:58:17,320 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9dd2d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 22:58:17,340 : INFO : collecting all words and their counts\n",
      "2022-10-04 22:58:17,341 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-10-04 22:58:17,652 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2022-10-04 22:58:17,957 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2022-10-04 22:58:18,384 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2022-10-04 22:58:18,827 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2022-10-04 22:58:19,305 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2022-10-04 22:58:19,771 : INFO : PROGRESS: at sentence #60000, processed 11013727 words, keeping 76787 word types\n",
      "2022-10-04 22:58:20,079 : INFO : PROGRESS: at sentence #70000, processed 12637529 words, keeping 83200 word types\n",
      "2022-10-04 22:58:20,389 : INFO : PROGRESS: at sentence #80000, processed 14099755 words, keeping 88460 word types\n",
      "2022-10-04 22:58:20,747 : INFO : PROGRESS: at sentence #90000, processed 15662153 words, keeping 93358 word types\n",
      "2022-10-04 22:58:21,079 : INFO : PROGRESS: at sentence #100000, processed 17164491 words, keeping 97887 word types\n",
      "2022-10-04 22:58:21,451 : INFO : PROGRESS: at sentence #110000, processed 18652296 words, keeping 102133 word types\n",
      "2022-10-04 22:58:21,758 : INFO : PROGRESS: at sentence #120000, processed 20152533 words, keeping 105924 word types\n",
      "2022-10-04 22:58:22,065 : INFO : PROGRESS: at sentence #130000, processed 21684334 words, keeping 110105 word types\n",
      "2022-10-04 22:58:22,403 : INFO : PROGRESS: at sentence #140000, processed 23330210 words, keeping 114109 word types\n",
      "2022-10-04 22:58:22,641 : INFO : PROGRESS: at sentence #150000, processed 24838758 words, keeping 118175 word types\n",
      "2022-10-04 22:58:22,997 : INFO : PROGRESS: at sentence #160000, processed 26390914 words, keeping 118671 word types\n",
      "2022-10-04 22:58:23,356 : INFO : PROGRESS: at sentence #170000, processed 27913920 words, keeping 123357 word types\n",
      "2022-10-04 22:58:23,681 : INFO : PROGRESS: at sentence #180000, processed 29535616 words, keeping 126749 word types\n",
      "2022-10-04 22:58:24,035 : INFO : PROGRESS: at sentence #190000, processed 31096463 words, keeping 129848 word types\n",
      "2022-10-04 22:58:24,399 : INFO : PROGRESS: at sentence #200000, processed 32805275 words, keeping 133256 word types\n",
      "2022-10-04 22:58:24,770 : INFO : PROGRESS: at sentence #210000, processed 34434202 words, keeping 136365 word types\n",
      "2022-10-04 22:58:25,116 : INFO : PROGRESS: at sentence #220000, processed 36083486 words, keeping 139419 word types\n",
      "2022-10-04 22:58:25,364 : INFO : PROGRESS: at sentence #230000, processed 37571766 words, keeping 142400 word types\n",
      "2022-10-04 22:58:25,698 : INFO : PROGRESS: at sentence #240000, processed 39138194 words, keeping 145233 word types\n",
      "2022-10-04 22:58:26,050 : INFO : PROGRESS: at sentence #250000, processed 40695053 words, keeping 147967 word types\n",
      "2022-10-04 22:58:26,216 : INFO : collected 150060 word types from a corpus of 41519359 raw words and 255404 sentences\n",
      "2022-10-04 22:58:26,216 : INFO : Creating a fresh vocabulary\n",
      "2022-10-04 22:58:26,657 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 70537 unique words (47.01% of original 150060, drops 79523)', 'datetime': '2022-10-04T22:58:26.657853', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-04 22:58:26,658 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 41439836 word corpus (99.81% of original 41519359, drops 79523)', 'datetime': '2022-10-04T22:58:26.658854', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-04 22:58:27,135 : INFO : deleting the raw counts dictionary of 150060 items\n",
      "2022-10-04 22:58:27,140 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2022-10-04 22:58:27,141 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 30349251.36700416 word corpus (73.2%% of prior 41439836)', 'datetime': '2022-10-04T22:58:27.141734', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-10-04 22:58:28,069 : INFO : estimated required memory for 70537 words and 100 dimensions: 91698100 bytes\n",
      "2022-10-04 22:58:28,070 : INFO : resetting layer weights\n",
      "2022-10-04 22:58:28,110 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-10-04T22:58:28.110110', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-10-04 22:58:28,111 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 70537 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-10-04T22:58:28.111111', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-10-04 22:58:29,119 : INFO : EPOCH 0 - PROGRESS: at 5.77% examples, 1779932 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:30,121 : INFO : EPOCH 0 - PROGRESS: at 10.97% examples, 1765589 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:31,122 : INFO : EPOCH 0 - PROGRESS: at 16.16% examples, 1786157 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:32,123 : INFO : EPOCH 0 - PROGRESS: at 20.70% examples, 1771485 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:33,130 : INFO : EPOCH 0 - PROGRESS: at 26.23% examples, 1780199 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:34,137 : INFO : EPOCH 0 - PROGRESS: at 28.71% examples, 1593735 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:35,143 : INFO : EPOCH 0 - PROGRESS: at 31.29% examples, 1466359 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:58:36,150 : INFO : EPOCH 0 - PROGRESS: at 37.62% examples, 1510799 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:37,153 : INFO : EPOCH 0 - PROGRESS: at 44.24% examples, 1544080 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:38,162 : INFO : EPOCH 0 - PROGRESS: at 50.65% examples, 1571004 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:58:39,168 : INFO : EPOCH 0 - PROGRESS: at 56.74% examples, 1591139 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:40,169 : INFO : EPOCH 0 - PROGRESS: at 62.95% examples, 1608498 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:41,171 : INFO : EPOCH 0 - PROGRESS: at 69.25% examples, 1624776 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:42,175 : INFO : EPOCH 0 - PROGRESS: at 75.28% examples, 1636922 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:43,180 : INFO : EPOCH 0 - PROGRESS: at 81.15% examples, 1650620 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:44,189 : INFO : EPOCH 0 - PROGRESS: at 87.16% examples, 1658531 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:45,272 : INFO : EPOCH 0 - PROGRESS: at 90.28% examples, 1604777 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:58:46,273 : INFO : EPOCH 0 - PROGRESS: at 92.48% examples, 1551223 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:47,280 : INFO : EPOCH 0 - PROGRESS: at 98.53% examples, 1562310 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:47,503 : INFO : EPOCH 0: training on 41519359 raw words (30351752 effective words) took 19.4s, 1565760 effective words/s\n",
      "2022-10-04 22:58:48,511 : INFO : EPOCH 1 - PROGRESS: at 5.57% examples, 1711647 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:49,537 : INFO : EPOCH 1 - PROGRESS: at 10.48% examples, 1651796 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:50,543 : INFO : EPOCH 1 - PROGRESS: at 10.87% examples, 1153635 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:58:51,550 : INFO : EPOCH 1 - PROGRESS: at 15.19% examples, 1247114 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:52,552 : INFO : EPOCH 1 - PROGRESS: at 20.04% examples, 1354016 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 22:58:53,554 : INFO : EPOCH 1 - PROGRESS: at 25.24% examples, 1430451 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:54,555 : INFO : EPOCH 1 - PROGRESS: at 31.95% examples, 1487188 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:58:55,563 : INFO : EPOCH 1 - PROGRESS: at 38.26% examples, 1527614 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:56,574 : INFO : EPOCH 1 - PROGRESS: at 44.83% examples, 1556132 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:58:57,576 : INFO : EPOCH 1 - PROGRESS: at 51.06% examples, 1579336 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:58,580 : INFO : EPOCH 1 - PROGRESS: at 57.27% examples, 1600936 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:58:59,583 : INFO : EPOCH 1 - PROGRESS: at 63.50% examples, 1616732 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:59:00,591 : INFO : EPOCH 1 - PROGRESS: at 69.56% examples, 1628847 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:01,592 : INFO : EPOCH 1 - PROGRESS: at 75.44% examples, 1637596 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:02,595 : INFO : EPOCH 1 - PROGRESS: at 80.80% examples, 1640640 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:03,606 : INFO : EPOCH 1 - PROGRESS: at 86.36% examples, 1642230 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:04,686 : INFO : EPOCH 1 - PROGRESS: at 90.90% examples, 1613011 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:05,688 : INFO : EPOCH 1 - PROGRESS: at 91.63% examples, 1535502 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:06,690 : INFO : EPOCH 1 - PROGRESS: at 97.64% examples, 1547364 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:07,062 : INFO : EPOCH 1: training on 41519359 raw words (30351367 effective words) took 19.6s, 1552150 effective words/s\n",
      "2022-10-04 22:59:08,078 : INFO : EPOCH 2 - PROGRESS: at 3.23% examples, 993198 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:09,079 : INFO : EPOCH 2 - PROGRESS: at 4.34% examples, 663305 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:10,081 : INFO : EPOCH 2 - PROGRESS: at 9.82% examples, 1032152 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:11,090 : INFO : EPOCH 2 - PROGRESS: at 14.80% examples, 1218478 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:12,091 : INFO : EPOCH 2 - PROGRESS: at 19.71% examples, 1333789 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:13,091 : INFO : EPOCH 2 - PROGRESS: at 24.64% examples, 1410087 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:14,095 : INFO : EPOCH 2 - PROGRESS: at 31.11% examples, 1459308 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:59:15,100 : INFO : EPOCH 2 - PROGRESS: at 37.16% examples, 1494230 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:16,110 : INFO : EPOCH 2 - PROGRESS: at 43.54% examples, 1522562 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:17,114 : INFO : EPOCH 2 - PROGRESS: at 49.80% examples, 1546906 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:18,117 : INFO : EPOCH 2 - PROGRESS: at 55.47% examples, 1557673 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:19,197 : INFO : EPOCH 2 - PROGRESS: at 60.75% examples, 1544917 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:59:20,263 : INFO : EPOCH 2 - PROGRESS: at 61.20% examples, 1429995 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:59:21,269 : INFO : EPOCH 2 - PROGRESS: at 66.01% examples, 1425634 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:22,327 : INFO : EPOCH 2 - PROGRESS: at 66.55% examples, 1337088 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:23,328 : INFO : EPOCH 2 - PROGRESS: at 72.49% examples, 1365048 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:59:24,335 : INFO : EPOCH 2 - PROGRESS: at 78.23% examples, 1387536 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:59:25,339 : INFO : EPOCH 2 - PROGRESS: at 83.76% examples, 1403071 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:26,342 : INFO : EPOCH 2 - PROGRESS: at 90.00% examples, 1423923 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:27,349 : INFO : EPOCH 2 - PROGRESS: at 95.86% examples, 1437647 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:28,022 : INFO : EPOCH 2: training on 41519359 raw words (30348306 effective words) took 21.0s, 1448263 effective words/s\n",
      "2022-10-04 22:59:29,030 : INFO : EPOCH 3 - PROGRESS: at 5.05% examples, 1556357 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:59:30,042 : INFO : EPOCH 3 - PROGRESS: at 10.19% examples, 1621293 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:31,042 : INFO : EPOCH 3 - PROGRESS: at 15.10% examples, 1663082 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:32,044 : INFO : EPOCH 3 - PROGRESS: at 19.93% examples, 1688710 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:33,046 : INFO : EPOCH 3 - PROGRESS: at 25.05% examples, 1713348 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:34,050 : INFO : EPOCH 3 - PROGRESS: at 31.19% examples, 1707126 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:35,145 : INFO : EPOCH 3 - PROGRESS: at 36.27% examples, 1649366 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:59:36,199 : INFO : EPOCH 3 - PROGRESS: at 36.77% examples, 1454186 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:37,292 : INFO : EPOCH 3 - PROGRESS: at 42.16% examples, 1443457 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:38,376 : INFO : EPOCH 3 - PROGRESS: at 42.68% examples, 1308205 words/s, in_qsize 19, out_qsize 1\n",
      "2022-10-04 22:59:39,385 : INFO : EPOCH 3 - PROGRESS: at 49.07% examples, 1348823 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:40,499 : INFO : EPOCH 3 - PROGRESS: at 53.62% examples, 1339113 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:41,504 : INFO : EPOCH 3 - PROGRESS: at 54.27% examples, 1253136 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:42,511 : INFO : EPOCH 3 - PROGRESS: at 60.64% examples, 1291919 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:43,521 : INFO : EPOCH 3 - PROGRESS: at 67.05% examples, 1326801 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:44,524 : INFO : EPOCH 3 - PROGRESS: at 73.24% examples, 1358353 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:45,531 : INFO : EPOCH 3 - PROGRESS: at 78.78% examples, 1378487 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:46,537 : INFO : EPOCH 3 - PROGRESS: at 84.43% examples, 1396850 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:47,541 : INFO : EPOCH 3 - PROGRESS: at 90.52% examples, 1414465 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:48,542 : INFO : EPOCH 3 - PROGRESS: at 96.63% examples, 1432728 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:49,089 : INFO : EPOCH 3: training on 41519359 raw words (30351263 effective words) took 21.1s, 1441146 effective words/s\n",
      "2022-10-04 22:59:50,103 : INFO : EPOCH 4 - PROGRESS: at 0.77% examples, 258195 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:51,109 : INFO : EPOCH 4 - PROGRESS: at 4.30% examples, 655325 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 22:59:52,158 : INFO : EPOCH 4 - PROGRESS: at 9.28% examples, 945239 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:53,205 : INFO : EPOCH 4 - PROGRESS: at 9.74% examples, 746078 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 22:59:54,288 : INFO : EPOCH 4 - PROGRESS: at 11.94% examples, 752791 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:55,294 : INFO : EPOCH 4 - PROGRESS: at 13.62% examples, 723467 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:56,422 : INFO : EPOCH 4 - PROGRESS: at 16.48% examples, 747831 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 22:59:57,422 : INFO : EPOCH 4 - PROGRESS: at 18.17% examples, 733233 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:58,554 : INFO : EPOCH 4 - PROGRESS: at 19.73% examples, 709166 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 22:59:59,557 : INFO : EPOCH 4 - PROGRESS: at 22.81% examples, 742550 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:00,561 : INFO : EPOCH 4 - PROGRESS: at 28.71% examples, 836531 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:01,565 : INFO : EPOCH 4 - PROGRESS: at 35.08% examples, 915053 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:02,571 : INFO : EPOCH 4 - PROGRESS: at 41.61% examples, 981067 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:03,574 : INFO : EPOCH 4 - PROGRESS: at 47.97% examples, 1037443 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 23:00:04,578 : INFO : EPOCH 4 - PROGRESS: at 54.15% examples, 1088245 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:05,579 : INFO : EPOCH 4 - PROGRESS: at 60.48% examples, 1132362 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:06,704 : INFO : EPOCH 4 - PROGRESS: at 66.49% examples, 1157821 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:00:07,793 : INFO : EPOCH 4 - PROGRESS: at 66.99% examples, 1098627 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:00:08,884 : INFO : EPOCH 4 - PROGRESS: at 69.19% examples, 1070587 words/s, in_qsize 19, out_qsize 1\n",
      "2022-10-04 23:00:09,892 : INFO : EPOCH 4 - PROGRESS: at 70.50% examples, 1038762 words/s, in_qsize 20, out_qsize 2\n",
      "2022-10-04 23:00:10,895 : INFO : EPOCH 4 - PROGRESS: at 76.46% examples, 1073551 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:11,931 : INFO : EPOCH 4 - PROGRESS: at 79.80% examples, 1069958 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:12,938 : INFO : EPOCH 4 - PROGRESS: at 81.05% examples, 1041366 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:13,939 : INFO : EPOCH 4 - PROGRESS: at 86.41% examples, 1064523 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:14,946 : INFO : EPOCH 4 - PROGRESS: at 92.44% examples, 1088724 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:15,952 : INFO : EPOCH 4 - PROGRESS: at 98.54% examples, 1114490 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:16,174 : INFO : EPOCH 4: training on 41519359 raw words (30347135 effective words) took 27.1s, 1120712 effective words/s\n",
      "2022-10-04 23:00:16,175 : INFO : Word2Vec lifecycle event {'msg': 'training on 207596795 raw words (151749823 effective words) took 108.1s, 1404275 effective words/s', 'datetime': '2022-10-04T23:00:16.175002', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-10-04 23:00:16,175 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=70537, vector_size=100, alpha=0.025>', 'datetime': '2022-10-04T23:00:16.175002', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n",
      "2022-10-04 23:00:16,176 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2022-10-04 23:00:16,177 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 70537 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-10-04T23:00:16.176002', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-10-04 23:00:17,193 : INFO : EPOCH 0 - PROGRESS: at 5.52% examples, 1686121 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:18,199 : INFO : EPOCH 0 - PROGRESS: at 10.71% examples, 1701156 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:19,205 : INFO : EPOCH 0 - PROGRESS: at 15.76% examples, 1725466 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:20,208 : INFO : EPOCH 0 - PROGRESS: at 20.54% examples, 1745091 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:21,212 : INFO : EPOCH 0 - PROGRESS: at 25.88% examples, 1755111 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:22,215 : INFO : EPOCH 0 - PROGRESS: at 31.85% examples, 1731409 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:23,279 : INFO : EPOCH 0 - PROGRESS: at 35.88% examples, 1639780 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:24,280 : INFO : EPOCH 0 - PROGRESS: at 36.80% examples, 1468141 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:25,295 : INFO : EPOCH 0 - PROGRESS: at 39.64% examples, 1393876 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:26,297 : INFO : EPOCH 0 - PROGRESS: at 41.65% examples, 1307827 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:27,315 : INFO : EPOCH 0 - PROGRESS: at 45.06% examples, 1272993 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:28,320 : INFO : EPOCH 0 - PROGRESS: at 46.69% examples, 1206102 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:29,329 : INFO : EPOCH 0 - PROGRESS: at 51.52% examples, 1219773 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:30,383 : INFO : EPOCH 0 - PROGRESS: at 52.00% examples, 1139416 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:31,384 : INFO : EPOCH 0 - PROGRESS: at 57.91% examples, 1178729 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:32,387 : INFO : EPOCH 0 - PROGRESS: at 64.16% examples, 1214753 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:33,391 : INFO : EPOCH 0 - PROGRESS: at 69.73% examples, 1241163 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:00:34,395 : INFO : EPOCH 0 - PROGRESS: at 75.56% examples, 1268476 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:35,408 : INFO : EPOCH 0 - PROGRESS: at 81.51% examples, 1298563 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:36,414 : INFO : EPOCH 0 - PROGRESS: at 87.61% examples, 1323321 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:37,415 : INFO : EPOCH 0 - PROGRESS: at 93.60% examples, 1342140 words/s, in_qsize 17, out_qsize 1\n",
      "2022-10-04 23:00:38,427 : INFO : EPOCH 0 - PROGRESS: at 99.20% examples, 1354056 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:38,543 : INFO : EPOCH 0: training on 41519359 raw words (30345502 effective words) took 22.4s, 1357191 effective words/s\n",
      "2022-10-04 23:00:39,704 : INFO : EPOCH 1 - PROGRESS: at 1.63% examples, 444896 words/s, in_qsize 20, out_qsize 4\n",
      "2022-10-04 23:00:40,703 : INFO : EPOCH 1 - PROGRESS: at 4.94% examples, 707251 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:41,769 : INFO : EPOCH 1 - PROGRESS: at 9.45% examples, 919553 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:00:42,834 : INFO : EPOCH 1 - PROGRESS: at 9.85% examples, 729607 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:43,838 : INFO : EPOCH 1 - PROGRESS: at 14.84% examples, 929577 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:44,931 : INFO : EPOCH 1 - PROGRESS: at 16.39% examples, 854088 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:45,932 : INFO : EPOCH 1 - PROGRESS: at 19.13% examples, 875534 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:46,936 : INFO : EPOCH 1 - PROGRESS: at 23.89% examples, 979554 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:47,939 : INFO : EPOCH 1 - PROGRESS: at 29.92% examples, 1057527 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:48,947 : INFO : EPOCH 1 - PROGRESS: at 36.05% examples, 1123288 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:49,949 : INFO : EPOCH 1 - PROGRESS: at 42.18% examples, 1173440 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:50,958 : INFO : EPOCH 1 - PROGRESS: at 48.37% examples, 1219249 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:51,960 : INFO : EPOCH 1 - PROGRESS: at 54.15% examples, 1256488 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:52,965 : INFO : EPOCH 1 - PROGRESS: at 60.25% examples, 1290308 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:53,969 : INFO : EPOCH 1 - PROGRESS: at 66.03% examples, 1313366 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:54,977 : INFO : EPOCH 1 - PROGRESS: at 71.79% examples, 1339175 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:00:56,118 : INFO : EPOCH 1 - PROGRESS: at 73.66% examples, 1281370 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:00:57,122 : INFO : EPOCH 1 - PROGRESS: at 76.78% examples, 1264811 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:00:58,133 : INFO : EPOCH 1 - PROGRESS: at 77.67% examples, 1214537 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:00:59,202 : INFO : EPOCH 1 - PROGRESS: at 80.04% examples, 1186942 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:00,220 : INFO : EPOCH 1 - PROGRESS: at 80.56% examples, 1138479 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:01,243 : INFO : EPOCH 1 - PROGRESS: at 84.69% examples, 1142965 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:01:02,281 : INFO : EPOCH 1 - PROGRESS: at 85.22% examples, 1099904 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:03,282 : INFO : EPOCH 1 - PROGRESS: at 91.39% examples, 1125761 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:04,287 : INFO : EPOCH 1 - PROGRESS: at 97.57% examples, 1152112 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 23:01:04,659 : INFO : EPOCH 1: training on 41519359 raw words (30349872 effective words) took 26.1s, 1162367 effective words/s\n",
      "2022-10-04 23:01:05,670 : INFO : EPOCH 2 - PROGRESS: at 5.73% examples, 1757816 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:06,679 : INFO : EPOCH 2 - PROGRESS: at 11.11% examples, 1784449 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:07,686 : INFO : EPOCH 2 - PROGRESS: at 16.24% examples, 1785872 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:08,696 : INFO : EPOCH 2 - PROGRESS: at 20.97% examples, 1787759 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:09,703 : INFO : EPOCH 2 - PROGRESS: at 26.61% examples, 1790034 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:10,705 : INFO : EPOCH 2 - PROGRESS: at 33.05% examples, 1787821 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:11,707 : INFO : EPOCH 2 - PROGRESS: at 39.06% examples, 1778343 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:12,710 : INFO : EPOCH 2 - PROGRESS: at 45.17% examples, 1765058 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:13,712 : INFO : EPOCH 2 - PROGRESS: at 51.22% examples, 1763096 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:14,777 : INFO : EPOCH 2 - PROGRESS: at 56.31% examples, 1726420 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:01:15,862 : INFO : EPOCH 2 - PROGRESS: at 56.93% examples, 1574701 words/s, in_qsize 19, out_qsize 1\n",
      "2022-10-04 23:01:16,870 : INFO : EPOCH 2 - PROGRESS: at 63.03% examples, 1589927 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:17,872 : INFO : EPOCH 2 - PROGRESS: at 69.25% examples, 1605741 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:18,874 : INFO : EPOCH 2 - PROGRESS: at 75.42% examples, 1622515 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:19,885 : INFO : EPOCH 2 - PROGRESS: at 81.23% examples, 1634746 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:20,888 : INFO : EPOCH 2 - PROGRESS: at 87.09% examples, 1641502 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:21,895 : INFO : EPOCH 2 - PROGRESS: at 93.30% examples, 1649466 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:22,899 : INFO : EPOCH 2 - PROGRESS: at 99.56% examples, 1657844 words/s, in_qsize 16, out_qsize 1\n",
      "2022-10-04 23:01:22,955 : INFO : EPOCH 2: training on 41519359 raw words (30347722 effective words) took 18.3s, 1659315 effective words/s\n",
      "2022-10-04 23:01:23,962 : INFO : EPOCH 3 - PROGRESS: at 5.60% examples, 1723703 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:24,969 : INFO : EPOCH 3 - PROGRESS: at 10.87% examples, 1743477 words/s, in_qsize 16, out_qsize 3\n",
      "2022-10-04 23:01:25,970 : INFO : EPOCH 3 - PROGRESS: at 15.85% examples, 1747224 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:26,971 : INFO : EPOCH 3 - PROGRESS: at 20.55% examples, 1753468 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:27,976 : INFO : EPOCH 3 - PROGRESS: at 25.62% examples, 1746122 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:29,013 : INFO : EPOCH 3 - PROGRESS: at 26.14% examples, 1469656 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:30,022 : INFO : EPOCH 3 - PROGRESS: at 30.62% examples, 1435380 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:31,023 : INFO : EPOCH 3 - PROGRESS: at 36.80% examples, 1474641 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:32,032 : INFO : EPOCH 3 - PROGRESS: at 43.18% examples, 1506852 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:33,035 : INFO : EPOCH 3 - PROGRESS: at 49.59% examples, 1536288 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:34,038 : INFO : EPOCH 3 - PROGRESS: at 55.82% examples, 1562493 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:35,059 : INFO : EPOCH 3 - PROGRESS: at 57.29% examples, 1465837 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:36,065 : INFO : EPOCH 3 - PROGRESS: at 60.83% examples, 1431758 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:37,065 : INFO : EPOCH 3 - PROGRESS: at 66.84% examples, 1453137 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:38,069 : INFO : EPOCH 3 - PROGRESS: at 72.98% examples, 1477808 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:39,071 : INFO : EPOCH 3 - PROGRESS: at 78.67% examples, 1495269 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:40,076 : INFO : EPOCH 3 - PROGRESS: at 84.41% examples, 1510080 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:41,085 : INFO : EPOCH 3 - PROGRESS: at 90.54% examples, 1523109 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:42,098 : INFO : EPOCH 3 - PROGRESS: at 96.60% examples, 1535237 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:42,632 : INFO : EPOCH 3: training on 41519359 raw words (30349417 effective words) took 19.7s, 1542828 effective words/s\n",
      "2022-10-04 23:01:43,657 : INFO : EPOCH 4 - PROGRESS: at 0.74% examples, 242080 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:01:44,690 : INFO : EPOCH 4 - PROGRESS: at 3.56% examples, 538867 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:01:45,742 : INFO : EPOCH 4 - PROGRESS: at 4.06% examples, 405035 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:46,929 : INFO : EPOCH 4 - PROGRESS: at 8.41% examples, 606708 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:47,936 : INFO : EPOCH 4 - PROGRESS: at 9.05% examples, 533475 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:49,027 : INFO : EPOCH 4 - PROGRESS: at 11.43% examples, 580728 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:50,033 : INFO : EPOCH 4 - PROGRESS: at 13.29% examples, 591260 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:01:51,043 : INFO : EPOCH 4 - PROGRESS: at 18.39% examples, 736374 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:52,044 : INFO : EPOCH 4 - PROGRESS: at 23.25% examples, 846223 words/s, in_qsize 20, out_qsize 2\n",
      "2022-10-04 23:01:53,054 : INFO : EPOCH 4 - PROGRESS: at 29.19% examples, 933769 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:54,057 : INFO : EPOCH 4 - PROGRESS: at 35.27% examples, 1004030 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:01:55,064 : INFO : EPOCH 4 - PROGRESS: at 41.65% examples, 1064855 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:56,068 : INFO : EPOCH 4 - PROGRESS: at 47.93% examples, 1117650 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:57,070 : INFO : EPOCH 4 - PROGRESS: at 53.93% examples, 1163171 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:01:58,071 : INFO : EPOCH 4 - PROGRESS: at 59.94% examples, 1199772 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:01:59,127 : INFO : EPOCH 4 - PROGRESS: at 65.46% examples, 1217137 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:00,139 : INFO : EPOCH 4 - PROGRESS: at 65.89% examples, 1154932 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:01,187 : INFO : EPOCH 4 - PROGRESS: at 69.15% examples, 1141547 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:02,187 : INFO : EPOCH 4 - PROGRESS: at 69.87% examples, 1094547 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:03,193 : INFO : EPOCH 4 - PROGRESS: at 75.93% examples, 1129670 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:04,328 : INFO : EPOCH 4 - PROGRESS: at 78.08% examples, 1102683 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:02:05,361 : INFO : EPOCH 4 - PROGRESS: at 80.80% examples, 1089343 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:02:06,443 : INFO : EPOCH 4 - PROGRESS: at 81.35% examples, 1046699 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:07,449 : INFO : EPOCH 4 - PROGRESS: at 86.64% examples, 1068378 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:08,450 : INFO : EPOCH 4 - PROGRESS: at 92.93% examples, 1096608 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:09,454 : INFO : EPOCH 4 - PROGRESS: at 99.07% examples, 1121932 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:09,587 : INFO : EPOCH 4: training on 41519359 raw words (30346456 effective words) took 26.9s, 1126162 effective words/s\n",
      "2022-10-04 23:02:10,646 : INFO : EPOCH 5 - PROGRESS: at 3.05% examples, 899706 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:11,646 : INFO : EPOCH 5 - PROGRESS: at 4.02% examples, 605108 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:12,748 : INFO : EPOCH 5 - PROGRESS: at 9.33% examples, 923036 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:13,837 : INFO : EPOCH 5 - PROGRESS: at 9.68% examples, 716248 words/s, in_qsize 20, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 23:02:14,871 : INFO : EPOCH 5 - PROGRESS: at 13.63% examples, 851549 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:02:15,957 : INFO : EPOCH 5 - PROGRESS: at 14.05% examples, 729935 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:17,074 : INFO : EPOCH 5 - PROGRESS: at 16.33% examples, 726032 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:02:18,083 : INFO : EPOCH 5 - PROGRESS: at 18.03% examples, 713399 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:19,092 : INFO : EPOCH 5 - PROGRESS: at 23.10% examples, 831649 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:20,188 : INFO : EPOCH 5 - PROGRESS: at 23.73% examples, 768688 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:02:21,257 : INFO : EPOCH 5 - PROGRESS: at 26.45% examples, 769303 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:22,258 : INFO : EPOCH 5 - PROGRESS: at 27.27% examples, 726110 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:23,259 : INFO : EPOCH 5 - PROGRESS: at 33.52% examples, 800202 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:24,271 : INFO : EPOCH 5 - PROGRESS: at 39.46% examples, 861068 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:25,271 : INFO : EPOCH 5 - PROGRESS: at 45.90% examples, 918723 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:26,272 : INFO : EPOCH 5 - PROGRESS: at 51.99% examples, 970082 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:27,282 : INFO : EPOCH 5 - PROGRESS: at 58.18% examples, 1017540 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:28,291 : INFO : EPOCH 5 - PROGRESS: at 64.45% examples, 1056681 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:29,295 : INFO : EPOCH 5 - PROGRESS: at 70.27% examples, 1093257 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:30,307 : INFO : EPOCH 5 - PROGRESS: at 76.09% examples, 1123712 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:31,320 : INFO : EPOCH 5 - PROGRESS: at 78.03% examples, 1100125 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:32,320 : INFO : EPOCH 5 - PROGRESS: at 80.09% examples, 1079296 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:33,387 : INFO : EPOCH 5 - PROGRESS: at 82.38% examples, 1059958 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:34,399 : INFO : EPOCH 5 - PROGRESS: at 84.72% examples, 1046252 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:35,514 : INFO : EPOCH 5 - PROGRESS: at 86.44% examples, 1020700 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:02:36,517 : INFO : EPOCH 5 - PROGRESS: at 90.27% examples, 1022379 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:37,628 : INFO : EPOCH 5 - PROGRESS: at 94.28% examples, 1023575 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:38,632 : INFO : EPOCH 5 - PROGRESS: at 95.84% examples, 1003827 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:02:39,268 : INFO : EPOCH 5: training on 41519359 raw words (30348176 effective words) took 29.7s, 1022715 effective words/s\n",
      "2022-10-04 23:02:40,278 : INFO : EPOCH 6 - PROGRESS: at 5.48% examples, 1685253 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:41,284 : INFO : EPOCH 6 - PROGRESS: at 10.72% examples, 1711141 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:42,288 : INFO : EPOCH 6 - PROGRESS: at 15.85% examples, 1745165 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:43,296 : INFO : EPOCH 6 - PROGRESS: at 20.70% examples, 1764752 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:44,303 : INFO : EPOCH 6 - PROGRESS: at 26.27% examples, 1776100 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:45,304 : INFO : EPOCH 6 - PROGRESS: at 32.59% examples, 1769649 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:46,308 : INFO : EPOCH 6 - PROGRESS: at 38.53% examples, 1760072 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:47,368 : INFO : EPOCH 6 - PROGRESS: at 43.52% examples, 1700712 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:02:48,402 : INFO : EPOCH 6 - PROGRESS: at 43.87% examples, 1518277 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:49,405 : INFO : EPOCH 6 - PROGRESS: at 45.90% examples, 1421982 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:50,407 : INFO : EPOCH 6 - PROGRESS: at 47.77% examples, 1343804 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:51,527 : INFO : EPOCH 6 - PROGRESS: at 49.00% examples, 1249167 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:52,535 : INFO : EPOCH 6 - PROGRESS: at 53.21% examples, 1250147 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:53,537 : INFO : EPOCH 6 - PROGRESS: at 59.38% examples, 1286477 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:54,682 : INFO : EPOCH 6 - PROGRESS: at 60.28% examples, 1207902 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:55,683 : INFO : EPOCH 6 - PROGRESS: at 65.30% examples, 1219978 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:02:56,687 : INFO : EPOCH 6 - PROGRESS: at 71.36% examples, 1255793 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:02:57,695 : INFO : EPOCH 6 - PROGRESS: at 77.46% examples, 1287630 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:58,702 : INFO : EPOCH 6 - PROGRESS: at 83.48% examples, 1314953 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:02:59,702 : INFO : EPOCH 6 - PROGRESS: at 89.76% examples, 1340826 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:00,703 : INFO : EPOCH 6 - PROGRESS: at 95.82% examples, 1360093 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:01,363 : INFO : EPOCH 6: training on 41519359 raw words (30351485 effective words) took 22.1s, 1374059 effective words/s\n",
      "2022-10-04 23:03:02,372 : INFO : EPOCH 7 - PROGRESS: at 5.25% examples, 1622441 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:03,376 : INFO : EPOCH 7 - PROGRESS: at 9.81% examples, 1552198 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:04,376 : INFO : EPOCH 7 - PROGRESS: at 10.20% examples, 1083278 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:05,377 : INFO : EPOCH 7 - PROGRESS: at 14.36% examples, 1185842 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:06,388 : INFO : EPOCH 7 - PROGRESS: at 19.35% examples, 1308437 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:07,390 : INFO : EPOCH 7 - PROGRESS: at 20.80% examples, 1184963 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:03:08,393 : INFO : EPOCH 7 - PROGRESS: at 23.14% examples, 1126869 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:03:09,433 : INFO : EPOCH 7 - PROGRESS: at 26.36% examples, 1110046 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:10,446 : INFO : EPOCH 7 - PROGRESS: at 27.94% examples, 1032360 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:11,446 : INFO : EPOCH 7 - PROGRESS: at 34.45% examples, 1112510 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:12,450 : INFO : EPOCH 7 - PROGRESS: at 40.70% examples, 1173129 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:13,451 : INFO : EPOCH 7 - PROGRESS: at 47.18% examples, 1224453 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:03:14,452 : INFO : EPOCH 7 - PROGRESS: at 53.19% examples, 1266505 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:15,463 : INFO : EPOCH 7 - PROGRESS: at 59.65% examples, 1306983 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:03:16,463 : INFO : EPOCH 7 - PROGRESS: at 65.98% examples, 1340929 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:17,463 : INFO : EPOCH 7 - PROGRESS: at 71.90% examples, 1369346 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:18,466 : INFO : EPOCH 7 - PROGRESS: at 77.80% examples, 1393517 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:19,582 : INFO : EPOCH 7 - PROGRESS: at 81.35% examples, 1368225 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:20,588 : INFO : EPOCH 7 - PROGRESS: at 83.04% examples, 1322490 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:03:21,596 : INFO : EPOCH 7 - PROGRESS: at 84.43% examples, 1278200 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:22,679 : INFO : EPOCH 7 - PROGRESS: at 87.32% examples, 1253077 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:23,703 : INFO : EPOCH 7 - PROGRESS: at 87.95% examples, 1203096 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:24,795 : INFO : EPOCH 7 - PROGRESS: at 92.69% examples, 1204946 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:03:25,821 : INFO : EPOCH 7 - PROGRESS: at 93.20% examples, 1161145 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 23:03:26,879 : INFO : EPOCH 7 - PROGRESS: at 96.12% examples, 1146104 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:27,880 : INFO : EPOCH 7 - PROGRESS: at 97.81% examples, 1121251 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:28,204 : INFO : EPOCH 7: training on 41519359 raw words (30348033 effective words) took 26.8s, 1130977 effective words/s\n",
      "2022-10-04 23:03:29,219 : INFO : EPOCH 8 - PROGRESS: at 5.77% examples, 1765497 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:30,227 : INFO : EPOCH 8 - PROGRESS: at 11.11% examples, 1781107 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:31,229 : INFO : EPOCH 8 - PROGRESS: at 16.27% examples, 1791378 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:32,230 : INFO : EPOCH 8 - PROGRESS: at 21.02% examples, 1797331 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:33,242 : INFO : EPOCH 8 - PROGRESS: at 26.68% examples, 1796064 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:34,243 : INFO : EPOCH 8 - PROGRESS: at 33.04% examples, 1788709 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:35,333 : INFO : EPOCH 8 - PROGRESS: at 35.25% examples, 1608213 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:03:36,334 : INFO : EPOCH 8 - PROGRESS: at 38.30% examples, 1515583 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:37,371 : INFO : EPOCH 8 - PROGRESS: at 39.53% examples, 1382724 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:38,382 : INFO : EPOCH 8 - PROGRESS: at 43.76% examples, 1359183 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:03:39,389 : INFO : EPOCH 8 - PROGRESS: at 45.95% examples, 1289563 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:40,497 : INFO : EPOCH 8 - PROGRESS: at 48.45% examples, 1233743 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:03:41,567 : INFO : EPOCH 8 - PROGRESS: at 49.10% examples, 1147351 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:42,573 : INFO : EPOCH 8 - PROGRESS: at 52.16% examples, 1130018 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:43,574 : INFO : EPOCH 8 - PROGRESS: at 53.07% examples, 1075998 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:44,576 : INFO : EPOCH 8 - PROGRESS: at 59.28% examples, 1119167 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:03:45,577 : INFO : EPOCH 8 - PROGRESS: at 65.43% examples, 1155010 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:46,578 : INFO : EPOCH 8 - PROGRESS: at 71.22% examples, 1188405 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:47,584 : INFO : EPOCH 8 - PROGRESS: at 77.17% examples, 1219219 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:48,584 : INFO : EPOCH 8 - PROGRESS: at 83.04% examples, 1247366 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:49,590 : INFO : EPOCH 8 - PROGRESS: at 89.06% examples, 1271270 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:50,591 : INFO : EPOCH 8 - PROGRESS: at 94.97% examples, 1291113 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:51,673 : INFO : EPOCH 8 - PROGRESS: at 99.26% examples, 1284447 words/s, in_qsize 20, out_qsize 1\n",
      "2022-10-04 23:03:52,625 : INFO : EPOCH 8: training on 41519359 raw words (30348931 effective words) took 24.4s, 1243060 effective words/s\n",
      "2022-10-04 23:03:53,691 : INFO : EPOCH 9 - PROGRESS: at 1.92% examples, 574691 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:03:54,700 : INFO : EPOCH 9 - PROGRESS: at 4.22% examples, 628732 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:55,816 : INFO : EPOCH 9 - PROGRESS: at 4.92% examples, 476674 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:56,916 : INFO : EPOCH 9 - PROGRESS: at 7.79% examples, 564002 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:03:57,915 : INFO : EPOCH 9 - PROGRESS: at 8.57% examples, 502203 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:58,919 : INFO : EPOCH 9 - PROGRESS: at 13.22% examples, 691962 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:03:59,928 : INFO : EPOCH 9 - PROGRESS: at 18.47% examples, 851956 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:04:00,932 : INFO : EPOCH 9 - PROGRESS: at 23.25% examples, 958896 words/s, in_qsize 20, out_qsize 0\n",
      "2022-10-04 23:04:01,935 : INFO : EPOCH 9 - PROGRESS: at 29.10% examples, 1042216 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:04:02,935 : INFO : EPOCH 9 - PROGRESS: at 35.16% examples, 1109783 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:03,938 : INFO : EPOCH 9 - PROGRESS: at 41.74% examples, 1171927 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:04:04,942 : INFO : EPOCH 9 - PROGRESS: at 47.53% examples, 1209771 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:04:05,953 : INFO : EPOCH 9 - PROGRESS: at 53.17% examples, 1243289 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:04:06,953 : INFO : EPOCH 9 - PROGRESS: at 58.88% examples, 1270953 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:08,019 : INFO : EPOCH 9 - PROGRESS: at 59.49% examples, 1194215 words/s, in_qsize 19, out_qsize 1\n",
      "2022-10-04 23:04:09,057 : INFO : EPOCH 9 - PROGRESS: at 62.23% examples, 1167771 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:10,116 : INFO : EPOCH 9 - PROGRESS: at 62.60% examples, 1102747 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:04:11,149 : INFO : EPOCH 9 - PROGRESS: at 65.21% examples, 1079429 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:04:12,150 : INFO : EPOCH 9 - PROGRESS: at 67.23% examples, 1055625 words/s, in_qsize 18, out_qsize 1\n",
      "2022-10-04 23:04:13,187 : INFO : EPOCH 9 - PROGRESS: at 68.66% examples, 1023033 words/s, in_qsize 19, out_qsize 1\n",
      "2022-10-04 23:04:14,197 : INFO : EPOCH 9 - PROGRESS: at 72.23% examples, 1025961 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:15,198 : INFO : EPOCH 9 - PROGRESS: at 78.08% examples, 1059803 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:16,207 : INFO : EPOCH 9 - PROGRESS: at 83.83% examples, 1088346 words/s, in_qsize 17, out_qsize 2\n",
      "2022-10-04 23:04:17,209 : INFO : EPOCH 9 - PROGRESS: at 89.98% examples, 1116705 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:18,212 : INFO : EPOCH 9 - PROGRESS: at 96.06% examples, 1142330 words/s, in_qsize 19, out_qsize 0\n",
      "2022-10-04 23:04:18,846 : INFO : EPOCH 9: training on 41519359 raw words (30347887 effective words) took 26.2s, 1157707 effective words/s\n",
      "2022-10-04 23:04:18,849 : INFO : Word2Vec lifecycle event {'msg': 'training on 415193590 raw words (303483481 effective words) took 242.7s, 1250594 effective words/s', 'datetime': '2022-10-04T23:04:18.849192', 'gensim': '4.2.0', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(303483481, 415193590)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8400aac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filthy', 0.895108163356781),\n",
       " ('unclean', 0.8111907243728638),\n",
       " ('stained', 0.8079451322555542),\n",
       " ('grubby', 0.7981095314025879),\n",
       " ('dusty', 0.7923869490623474),\n",
       " ('smelly', 0.78857421875)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = \"dirty\"\n",
    "model.wv.most_similar (positive=w1,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e27d4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('horrified', 0.8209891319274902),\n",
       " ('amazed', 0.8154876828193665),\n",
       " ('appalled', 0.7777613401412964),\n",
       " ('astonished', 0.76986163854599),\n",
       " ('dismayed', 0.7686170935630798),\n",
       " ('stunned', 0.7485442757606506)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w2,topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e394547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792387"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"dusty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141992d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2624902"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cd40c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shower'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f1c15",
   "metadata": {},
   "source": [
    "# AI in the fabrics of society\n",
    "\n",
    "Notice that the accuracy of the training data is perfect, but it does not work on testing data. That is to say, when we use machine to classify whether a word is gender-based or not, it will make its own decision that is **sometimes not accurate** for future predictions (since **machine itself does not understand the meaning of vocabulary**)\n",
    "\n",
    "Although the accuracy sometimes is excellent for the machine learning algorithm, the problem is that sometimes it will cause some bias. For some vacabularies that is not a gender-based meaning, the algorithm will consider it to be a gender-related because of, for example, the occurance times of that words together with some other words(such as smoking may be considered to be a masculine word because it appears together with male more often than female)\n",
    "\n",
    "Here is an article regarding this gender-biased problem: \n",
    "\n",
    "Man is to Computer Programmer as Woman is to Homemaker? | by Sheldon Sebastian | Towards Data Science\n",
    "https://towardsdatascience.com/man-is-to-computer-programmer-as-woman-is-to-homemaker-e57b07cbde96\n",
    "\n",
    "### Hate Speech Content Moderation on Social Media Platforms\n",
    "\n",
    "Social Media companies have become a forefront for algorithms that can detect hate speech on their platforms. These companies are receiving pressure from their users, and governments to moderate their content to ensure safety, while still promoting autonomy.  These companies have developed various forms of NLPs to moderate hate speech.\n",
    "\n",
    "These algorithms have the ability to detect hate speech, but they are not perfect. The main problem these algorithms face are taking words out of context. The algorithms are sensitive to specific words, and it is difficult to indicate whether a specific word or phrase is being used as hate speech.  Another problem is that social norms change over time. Historical text, from recent or long ago, can contain words classified as hate speech, but were used commonly in texts written in that time period. \n",
    "\n",
    "Users who want to post hate speech have multiple ways to evade these algorithms. Users can input punctuation, use slang, or display the text in a picture instead of a comment.  These algorithms are best used on apps like Twitter and Reddit, because they consist of primarily words, and few images and videos.  Alternatively, apps like TikTok face a bigger challenge because their posts contain primarily videos, and include the opportunity for voiceovers and text in the video frames.\n",
    "\n",
    "Content moderation is a controversial issue because what is and isn’t hate speech is still subjective to different people.  These companies are making their own rules on how much to moderate, and the debate becomes more and more difficult as more sophisticated algorithms begin to be used.\n",
    "\n",
    "An example of how you would build an NLP to classify tweets as hate speech or not is linked here\n",
    "https://towardsdatascience.com/detecting-hate-tweets-twitter-sentiment-analysis-780d8a82d4f6\n",
    "\n",
    "A comprehensive review of TikToks hate speech content moderation, with an emphasis on algorithm evasion tactics on pages 42-44\n",
    "https://www.isdglobal.org/wp-content/uploads/2021/08/HateScape_v5.pdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad9cdb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Word Embeding Model: Glove\n",
    "#Reference: https://nlp.stanford.edu/projects/glove/\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embeddings_dict = {}\n",
    "#Download the GLOVE model from:\n",
    "#https://nlp.stanford.edu/projects/glove/\n",
    "with open(\"glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:],\"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4ea241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frog', 'snake', 'ape', 'toad', 'monkey']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nearest neighbors of frog\n",
    "def closest(embedding):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))\n",
    "words = []\n",
    "for a in closest(embeddings_dict[\"frog\"])[:5]:\n",
    "    words.append(a)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c99ef122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anocanda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "G:\\anocanda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAayklEQVR4nO3de3BV9b338feXEPOkUKCWqBDQwCmNGi4h2XUCCCJQwaoQOcMRHlqsHoeqpXVapQVbR+qjc3jESwc9avGoaAeEVgixCMaiVJQejiSEqxDkEiyBhwYsNw2BhO/zRxZ0BxIS2NnZCfm8Ztaw12/dvmvNzv6wLr+9zd0RERFpFesCRESkaVAgiIgIoEAQEZGAAkFERAAFgoiIBFrHuoD66tixo6ekpMS6DBGRZqWgoGC/uyfVZ95mEwgpKSnk5+fHugwRkWbFzHbVd15dMhIRESDKgWBmXc1suZltNrNNZvZA0D7NzErMbG0wfC+adYiISN2ifcmoAnjQ3deY2deBAjP7czDtWXd/KsrbFxGReorqGYK773X3NcHrI8BmIDma2zyX7OxsMjMzSUtLY9asWQC0bduWBx98kIyMDIYOHUppaSkA27dvZ8SIEWRmZjJw4EC2bNkSq7JFRBpFo91DMLMUoC/wP0HTJDNbb2avmtk3allmopnlm1n+qQ/qSLz66qsUFBSQn5/PzJkzOXDgAF9++SUZGRmsWbOGG264gd/85jcATJw4keeee46CggKeeuop7r///oi3LyLSlFljfLmdmbUFPgSecPeFZnY5sB9w4P8Andz97nOtIxQK+fk+ZbSosIQZeUXsOVhG5w6JdN25mM2r3geguLiYvLw8BgwYQHl5Oa1bt2bHjh2MHj2ajz/+mKSkJFJTU0+vq7y8nM2bN5/X9kVEYs3MCtw9VJ95o/7YqZnFAwuAOe6+EMDd94VNfxlY3NDbXVRYwtSFGyg7UQnA9vX/Q+FHebw2P5c7+n+LwYMHc+zYsZrq5eTJk3To0IG1a9c2dFkiIk1WtJ8yMuAVYLO7PxPW3ilsttuBjQ297Rl5RafDAOBk+VeQ0IaZKz5ny5YtrFq1qqr95EneeustAObOncv1119Pu3bt6NatG3/84x8BcHfWrVvX0CWKiDQp0T5DGAD8ANhgZmuDtoeBcWaWTtUlo2LgRw294T0Hy6qNJ3bL5EjhUlY/8+88UhAiKysLgDZt2rBp0yYyMzNp37498+fPB2DOnDncd999PP7445w4cYKxY8fSp0+fhi5TRKTJaJR7CA3hfO8hDJj+ASVnhAJAcodEVk4Zcnq8bdu2HD16tEFqFBFpas7nHsJF21N58vBUEuPjqrUlxscxeXhqLUuIiLRsF20gZPdN5j9G9yK5QyJG1ZnBf4zuRXbf6t0gdHYgLU1xcTE9e/aMdRnSBDWbL7e7ENl9k88KABERqdlFe4YgcjEoLi7m6quv5p577qFnz56MHz+eZcuWMWDAAHr06MEnn3zCF198QXZ2Nr179yYrK4v169cDMG3aNO6++24GDx5M9+7dmTlz5lnr37FjB3379mX16tU19s4/cuQI3bp148SJEwAcPnyYlJSU0+NykXH3ZjFkZma6SEuzc+dOj4uL8/Xr13tlZaVnZGT4XXfd5SdPnvRFixb5qFGjfNKkST5t2jR3d3///fe9T58+7u7+6KOPer9+/fzYsWNeWlrql156qR8/ftx37tzpaWlpvmXLFk9PT/fCwkJ3dx8yZIhv3brV3d1XrVrlN954o7u7//CHP/ScnBx3d//d737nP//5zxv1GEhkgHyv5+fsRX3JSKQ5Cu9hf6kf4rLOXenVqxcAaWlpDB06FDOjV69eFBcXs2vXLhYsWADAkCFDOHDgAIcOHQLglltuISEhgYSEBC677DL27avqE1paWsqoUaNYsGABaWlpHD16lL/+9a+MGTPmdB3l5eUA3HPPPTz55JNkZ2fz2muv8fLLLzfm4ZBGpEAQaULO7GG/7/AxDhxzFhWWkN03mVatWpGQkABAq1atqKiooHXrs/+Mq/qEcnpegLi4OCoqKgBo3749Xbt2ZeXKlaSlpZ2zd/6AAQMoLi7mww8/pLKyUjekL2K6hyDShJzZwx6qLuvOyCuqdZlBgwYxZ84cAP7yl7/QsWNH2rVrd87tXHLJJSxatIg33niDuXPn1tk7f8KECYwbN4677rrrQndNmgEFgkgTcmYP+7raoermcX5+Pr1792bKlCm8/vrr9dpWmzZtWLx4Mc8++yy5ubnMmTOHV155hT59+pCWlkZubu7pecePH88//vEPxo0bd347JM3KRdtTWaQ5qm8P+8b21ltvkZuby+9///uY1SAXpkl926mI1N/k4anV7iFA7HvY/+QnP2Hp0qUsWbIkZjVI41AgiDQhpzpShv+Ox+ThqTHtYPncc8/FbNvSuBQIIk2MethLrOimsoiIAAoEEREJKBBERARQIIiISECBICIigAJBREQCMQsEMxthZkVmts3MpsSqDhERqRKTQDCzOOA/gZuBa4FxZnZtLGoREZEqsTpDuA7Y5u473P04MA8YFaNaRESE2AVCMvC3sPHdQVs1ZjbRzPLNLL+0tLTRihMRaYliFQhWQ9tZX7vq7rPcPeTuoaSkpEYoS0Sk5YpVIOwGuoaNdwH2xKgWEREhdoGwGuhhZt3M7BJgLPB2jGoRERFi9G2n7l5hZpOAPCAOeNXdN8WiFhERqRKzr7929yWAfnFDRKSJUE9lEREBFAgiIhJQIIiICKBAEBGRgAJBREQABYKIiAQUCCIiAigQREQkoEAQERFAgSAiIgEFgoiIAAoEEREJKBBERARQIIiISECBICIigAJBREQCCgQREQEUCCIiEohaIJjZDDPbYmbrzSzHzDoE7SlmVmZma4PhpWjVICIi9RfNM4Q/Az3dvTewFZgaNm27u6cHw71RrEFEROopaoHg7u+5e0UwugroEq1tiYhI5BrrHsLdwNKw8W5mVmhmH5rZwNoWMrOJZpZvZvmlpaXRr1JEpAVrHcnCZrYMuKKGSb9y99xgnl8BFcCcYNpe4Ep3P2BmmcAiM0tz98NnrsTdZwGzAEKhkEdSq4iInFtEgeDuw8413czuBG4Fhrq7B8uUA+XB6wIz2w58G8iPpBYREYlMNJ8yGgH8Ehjp7l+FtSeZWVzwujvQA9gRrTpERKR+IjpDqMPzQALwZzMDWBU8UTQIeMzMKoBK4F53/yKKdYiISD1ELRDc/Vu1tC8AFkRruyIicmHUU1lERAAFgoiIBBQIIiICKBBERCSgQBAREUCBICIiAQWCiIgACgQREQkoEEREBFAgiIhIQIEgIiKAAkFERAIKBBERARQIIiISUCCIiAigQBARkYACQUREAAWCiIgEohYIZjbNzErMbG0wfC9s2lQz22ZmRWY2PFo1iIhI/UXtN5UDz7r7U+ENZnYtMBZIAzoDy8zs2+5eGeVaRETkHGJxyWgUMM/dy919J7ANuC4GdYiISJhoB8IkM1tvZq+a2TeCtmTgb2Hz7A7azmJmE80s38zyS0tLo1yqiEjLFlEgmNkyM9tYwzAKeBH4FyAd2As8fWqxGlblNa3f3We5e8jdQ0lJSZGUKiIidYjoHoK7D6vPfGb2MrA4GN0NdA2b3AXYE0kdIiISuWg+ZdQpbPR2YGPw+m1grJklmFk3oAfwSbTqEBGR+onmU0ZPmlk6VZeDioEfAbj7JjP7A/ApUAH8WE8YiYjEXtQCwd1/cI5pTwBPRGvbIiJy/tRTWUREAAWCiIgEFAgiIgIoEEREJKBAEBERQIEgIiIBBYKIiAAKBBERCSgQREQEUCCIiEhAgSAiIoACQUSkWZg5cybXXHMN48ePj9o2ov2byiIi0gBeeOEFli5dSrdu3U63VVRU0Lp1w32M6wxBRKSJu/fee9mxYwcjR46kffv2TJw4kZtuuokJEyawa9cuhg4dSu/evRk6dCiff/45ANu3bycrKwvgGjN7zMyO1rUdBYKISBP30ksv0blzZ5YvX87PfvYzCgoKyM3NZe7cuUyaNIkJEyawfv16xo8fz09/+lMAHnjgAR544AGAzdTzVynNvcafM25yQqGQ5+fnx7oMEZFGsaiwhBl5Rew5WEbnDol8NvNOPl1fyPPPP4+Z8eijjwLQsWNH9u7dS3x8PCdOnKBTp07s37+fb37zm+zbt4/4+PgCYAiwx93bnmubuocgItLELCosYerCDZSdqPoxyZKDZfzjq+MsWb8XgDZt2tS6rJld8HZ1yUhEpImZkVd0OgxOcYfnl287a97+/fszb948AObMmcP1118PQFZWFgsWLDg129j6bDdqZwhmNh9IDUY7AAfdPd3MUqi6plUUTFvl7vdGqw4RkeZmz8GyGtv/36EyuLR628yZM7n77ruZMWMGSUlJvPbaawD89re/5fvf/z7ANUAn4FBd243mbyrfceq1mT19RjHb3T09WtsWEWnOOndIpOSMUOhy36skd0hk2pT/Xa09JSWFDz744Kx1JCcns2rVKlq1anXqP+B13oSN+iUjq7qg9W/Am9HelojIxWDy8FQS4+OqtSXGxzF5eGotS5ytoKCA9PR0gGuB+4EH61om6k8Zmdkg4Bl3DwXjKcAmYCtwGPi1u39Uy7ITgYkAV155ZeauXbuiWquISFNx5lNGk4enkt03+bzXY2YFpz5/65w3kkAws2XAFTVM+pW75wbzvAhsc/eng/EEoK27HzCzTGARkObuh8+1LT12KiJy/s4nECK6h+Duw+oopDUwGsgMW6YcKA9eF5jZduDb1OP6loiIRE+07yEMA7a4++5TDWaWZGZxwevuQA9gR5TrEBGROkS7Y9pYzr6ZPAh4zMwqgErgXnf/Isp1iIhIHaIaCO7+wxraFgALzp5bRERiST2VRUQEUCCIiEhAgSAiIoACQUREAgoEEREBFAgiIhJQIIiICKBAEBGRgAJBREQABYKIiAQUCCIiAigQREQkoEAQERFAgSAiIgEFgoiIAAoEEREJKBBERARQIIiISCCiQDCzMWa2ycxOmlnojGlTzWybmRWZ2fCw9kwz2xBMm2lmFkkNIiLSMCI9Q9gIjAZWhDea2bXAWCANGAG8YGZxweQXgYlAj2AYEWENIiLSACIKBHff7O5FNUwaBcxz93J33wlsA64zs05AO3f/b3d34A0gO5IaRESkYUTrHkIy8Lew8d1BW3Lw+sx2ERGJsdZ1zWBmy4Arapj0K3fPrW2xGtr8HO21bXsiVZeXuPLKK+uoVEREIlFnILj7sAtY726ga9h4F2BP0N6lhvbatj0LmAUQCoVqDQ4REYlctC4ZvQ2MNbMEM+tG1c3jT9x9L3DEzLKCp4smALWdZYiISCOK9LHT281sN9APeMfM8gDcfRPwB+BT4F3gx+5eGSx2H/BfVN1o3g4sjaQGERFpGFb1sE/TFwqFPD8/P2rrP3jwIHPnzuX++++PeF3Tpk2jbdu2PPTQQw1QmYjIhTOzAncP1T2neiqfdvDgQV544YVYlyEiEjMKhMCUKVPYvn076enpTJ48mcmTJ9OzZ0969erF/PnzATh69ChDhw4lIyODXr16kZv7z9sfTzzxBKmpqQwbNoyiopq6ZoiING11PmXUUkyfPp2NGzeydu1aFixYwEsvvcS6devYv38/3/nOdxg0aBBJSUnk5OTQrl079u/fT1ZWFiNHjmTNmjXMmzePwsJCKioqyMjIIDMzM9a7JCJyXlp8ICwqLGFGXhG7dhXzxf4vWVRYwscff8y4ceOIi4vj8ssv54YbbmD16tXcfPPNPPzww6xYsYJWrVpRUlLCvn37+Oijj7j99tv52te+BsDIkSNjvFciIuevRQfCosISpi7cQNmJqgegKipPMnXhBr617wi9ep09/5w5cygtLaWgoID4+HhSUlI4duwYAPqOPhFp7lr0PYQZeUWnw8AuSeTk8TLKTlTyWauuzJ8/n8rKSkpLS1mxYgXXXXcdhw4d4rLLLiM+Pp7ly5eza9cuAAYNGkROTg5lZWUcOXKEP/3pT7HcLRGRC9KizxD2HCw7/TousR0Jydey55X7Sewe4rZBvenTpw9mxpNPPskVV1zB+PHjue222wiFQqSnp3P11VcDkJGRwR133EF6ejpXXXUVAwcOjNUuiYhcsBbdD2HA9A8oCQuFU5I7JLJyypAG3ZaISCyoH0I9TR6eSmJ8XLW2xPg4Jg9PjVFFIiKx06IvGWX3rfrm7Rl5Rew5WEbnDolMHp56ul1EpCVp0YEAVaGgABARaeGXjERE5J8UCCIiAigQREQkoEAQERFAgSAiIgEFgoiIAAoEEREJKBBERASIMBDMbIyZbTKzk2YWCmv/rpkVmNmG4N8hYdP+YmZFZrY2GC6LpAYREWkYkfZU3giMBn53Rvt+4DZ332NmPYE8ILw78Hh3b9hvqhMRkYhEFAjuvhnO/nEYdy8MG90E/C8zS3D38ki2JyIi0dMY9xD+FSg8IwxeCy4XPWLn+KkxM5toZvlmll9aWhr9SkVEWrA6A8HMlpnZxhqGUfVYNg34v8CPwprHu3svYGAw/KC25d19lruH3D2UlJRU996IiMgFq/OSkbsPu5AVm1kXIAeY4O7bw9ZXEvx7xMzmAtcBb1zINkREpOFE5ZKRmXUA3gGmuvvKsPbWZtYxeB0P3ErVjWkREYmxSB87vd3MdgP9gHfMLC+YNAn4FvDIGY+XJgB5ZrYeWAuUAC9HUoOIiDSMFv2byiIiFzv9prKIiJw3BYKIiAAKBBERCSgQREQEUCCIiEhAgSAiIoACQUREAgoEEREBFAgiIhJQIIiICKBAEBGRgAJBREQABYKIiAQUCCIiAigQREQkoEAQERFAgSAiIgEFgoiIAJH/pvIYM9tkZifNLBTWnmJmZWG/p/xS2LRMM9tgZtvMbKaZWSQ1iIhIw4j0DGEjMBpYUcO07e6eHgz3hrW/CEwEegTDiAhrEBGRBhBRILj7Zncvqu/8ZtYJaOfu/+3uDrwBZEdSg4iINIxo3kPoZmaFZvahmQ0M2pKB3WHz7A7aamRmE80s38zyS0tLo1iqiIi0rmsGM1sGXFHDpF+5e24ti+0FrnT3A2aWCSwyszSgpvsFXtu23X0WMAsgFArVOp+IiESuzkBw92Hnu1J3LwfKg9cFZrYd+DZVZwRdwmbtAuw53/WLiEjDi8olIzNLMrO44HV3qm4e73D3vcARM8sKni6aANR2liEiIo0o0sdObzez3UA/4B0zywsmDQLWm9k64C3gXnf/Iph2H/BfwDZgO7A0khpE5J9mz57NpEmTYl2GNFN1XjI6F3fPAXJqaF8ALKhlmXygZyTbFRGRhqeeyiJNxJdffsktt9xCnz596NmzJ/PnzyclJYVHH32UjIwMevXqxZYtWwD45JNP6N+/P3379qV///4UFZ399Pc777xDv3792L9/P++99x79+vUjIyODMWPGcPTo0cbePWkGFAgiTcS7775L586dWbduHRs3bmTEiKo+mx07dmTNmjXcd999PPXUUwBcffXVrFixgsLCQh577DEefvjhauvKyclh+vTpLFmyBIDHH3+cZcuWsWbNGkKhEM8880zj7pw0CxFdMhKRyCwqLGFGXhF7DpbxjRNHKVmSx6W//CW33norAwdWdd8ZPXo0AJmZmSxcuBCAQ4cOceedd/LZZ59hZpw4ceL0OpcvX05+fj7vvfce7dq1Y/HixXz66acMGDAAgOPHj9OvX79G3lNpDhQIIjGyqLCEqQs3UHaiEoAv4jvSftzTlH99L1OnTuWmm24CICEhAYC4uDgqKioAeOSRR7jxxhvJycmhuLiYwYMHn15v9+7d2bFjB1u3biUUCuHufPe73+XNN99s3B2UZkeXjERiZEZe0ekwAKg4coByWrO6dU8eeugh1qxZU+uyhw4dIjm5qpP/7Nmzq0276qqrWLhwIRMmTGDTpk1kZWWxcuVKtm3bBsBXX33F1q1bG36HpNlTIIjEyJ6DZdXGT5QWs/eNn7P62Xt44okn+PWvf13rsr/4xS+YOnUqAwYMoLKy8qzpqampzJkzhzFjxnD48GFmz57NuHHj6N27N1lZWadvTouEs6rvmGv6QqGQ5+fnx7oMkQYzYPoHlJwRCgDJHRJZOWVIDCqSi5GZFbh7qO45dYYgEjOTh6eSGB9XrS0xPo7Jw1NjVJG0dLqpLBIj2X2r7gGcesqoc4dEJg9PPd0u0tgUCCIxlN03WQEgTYYuGYmICKBAEBGRgAJBREQABYKIiAQUCCIiAjSjjmlmVgrsinUdF6AjsD/WRTQxOibV6XhUp+NRXaTH4yp3T6rPjM0mEJorM8uvby/BlkLHpDodj+p0PKprzOOhS0YiIgIoEEREJKBAiL5ZsS6gCdIxqU7Hozodj+oa7XjoHoKIiAA6QxARkYACQUREAAVC1JjZNDMrMbO1wfC9sGlTzWybmRWZ2fBY1tmYzGxEsM/bzGxKrOuJBTMrNrMNwXsiP2i71Mz+bGafBf9+I9Z1RouZvWpmfzezjWFtte5/S/hbqeWYxOTzQ4EQXc+6e3owLAEws2uBsUAaMAJ4wczizrWSi0Gwj/8J3AxcC4wLjkVLdGPwnjj1bPkU4H137wG8H4xfrGZT9b4PV+P+t6C/ldmcfUwgBp8fCoTGNwqY5+7l7r4T2AZcF+OaGsN1wDZ33+Hux4F5VB0LqToOrwevXweyY1dKdLn7CuCLM5pr2/8W8bdSyzGpTVSPiQIhuiaZ2frglPDUaXAy8LeweXYHbRe7lrrfZ3LgPTMrMLOJQdvl7r4XIPj3sphVFxu17X9Lf880+ueHAiECZrbMzDbWMIwCXgT+BUgH9gJPn1qshlW1hGd/W+p+n2mAu2dQdensx2Y2KNYFNWEt+T0Tk88P/YRmBNx9WH3mM7OXgcXB6G6ga9jkLsCeBi6tKWqp+12Nu+8J/v27meVQdbq/z8w6ufteM+sE/D2mRTa+2va/xb5n3H3fqdeN+fmhM4QoCd7Yp9wOnHqC4G1grJklmFk3oAfwSWPXFwOrgR5m1s3MLqHqxtjbMa6pUZlZGzP7+qnXwE1UvS/eBu4MZrsTyI1NhTFT2/631L+VmH1+6Awhep40s3SqTueKgR8BuPsmM/sD8ClQAfzY3StjVWRjcfcKM5sE5AFxwKvuvinGZTW2y4EcM4Oqv7257v6uma0G/mBm/w58DoyJYY1RZWZvAoOBjma2G3gUmE4N+99S/lZqOSaDY/H5oa+uEBERQJeMREQkoEAQERFAgSAiIgEFgoiIAAoEEREJKBBERARQIIiISOD/AwsVL0LkU530AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "vectors = [embeddings_dict[word] for word in words]\n",
    "Y = tsne.fit_transform(vectors[:5])\n",
    "pyplot.scatter(Y[:, 0], Y[:, 1])\n",
    "for i, word in enumerate(words):\n",
    "    pyplot.annotate(word, xy=(Y[i, 0], Y[i, 1]))\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41aa13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anocanda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "G:\\anocanda\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Comparisons man -> woman\n",
    "comparsions=['man','woman','tennes','drive','movie','dress']\n",
    "vectors = [embeddings_dict[word] for word in comparsions]\n",
    "Y = tsne.fit_transform(vectors[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "babdea8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.scatter(Y[:, 0], Y[:, 1])\n",
    "for i, word in enumerate(comparsions):\n",
    "    pyplot.annotate(word, xy=(Y[i, 0], Y[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51886e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
